{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304ae6f7-114f-4565-9c2f-9cbd965ff77b",
   "metadata": {},
   "source": [
    "# ðŸ§  Memory Management - Part 2 - Memory\n",
    "\n",
    "**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n",
    "\n",
    "In the previous notebook, you learned how **Sessions** manage conversation threads. Now you'll add **Memory** - a searchable, long-term knowledge store that persists across multiple conversations.\n",
    "\n",
    "### What is Memory â“\n",
    "\n",
    "Memory is a service that provides long-term knowledge storage for your agents. The key distinction:\n",
    "\n",
    "> **Session = Short-term memory** (single conversation)\n",
    "> \n",
    "> **Memory = Long-term knowledge** (across multiple conversations)\n",
    "\n",
    "Think of it in software engineering terms: **Session** is like application state (temporary), while **Memory** is like a database (persistent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a006d-cba1-4b1d-9183-ee843a999743",
   "metadata": {},
   "source": [
    "### ðŸ¤” Why Memory?\n",
    "\n",
    "Memory provides capabilities that Sessions alone cannot:\n",
    "\n",
    "| Capability | What It Means | Example |\n",
    "|------------|---------------|---------|\n",
    "| **Cross-Conversation Recall** | Access information from any past conversation | \"What preferences has this user mentioned across all chats?\" |\n",
    "| **Intelligent Extraction** | LLM-powered consolidation extracts key facts | Stores \"allergic to peanuts\" instead of 50 raw messages |\n",
    "| **Semantic Search** | Meaning-based retrieval, not just keyword matching | Query \"preferred hue\" matches \"favorite color is blue\" |\n",
    "| **Persistent Storage** | Survives application restarts | Build knowledge that grows over time |\n",
    "\n",
    "**Example:** Imagine talking to a personal assistant:\n",
    "- ðŸ—£ï¸ **Session**: They remember what you said 10 minutes ago in THIS conversation\n",
    "- ðŸ§  **Memory**: They remember your preferences from conversations LAST WEEK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126361a5-d670-4d59-b807-3d13004b70e1",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ What you'll learn:\n",
    "\n",
    "- âœ… Initialize MemoryService and integrate with your agent\n",
    "- âœ… Transfer session data to memory storage\n",
    "- âœ… Search and retrieve memories\n",
    "- âœ… Automate memory storage and retrieval\n",
    "- âœ… Understand memory consolidation (conceptual overview)\n",
    "\n",
    "#### ðŸ“ Implementation Note\n",
    "\n",
    "> This notebook uses `InMemoryMemoryService` for learning - it performs keyword matching and doesn't persist data. \n",
    ">\n",
    "> For production applications, use **Vertex AI Memory Bank** (covered in Day 5), which provides LLM-powered consolidation and semantic search with persistent cloud storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c37a29-777b-4eff-a931-a71b0bba696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools import load_memory, preload_memory\n",
    "from google.genai import types\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12261748-5c88-4b0c-af43-ad58e0415f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loads variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7b51eda-1a90-4b23-a27a-54a4720c2464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"Environment variable GOOGLE_API_KEY not found!\")\n",
    "\n",
    "print(\"Secret loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3e1dbb-5b96-4cd7-aebf-1b4c968f5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"âœ… Gemini API key setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19caf189-9ade-41e2-8b3c-de5b10090aff",
   "metadata": {},
   "source": [
    "### 1.4: Helper functions\n",
    "\n",
    "This helper function manages a complete conversation session, handling session creation/retrieval, query processing, and response streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47231c22-2f97-4c0f-b231-2469e8c6d7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "async def run_session(\n",
    "    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n",
    "):\n",
    "    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n",
    "    print(f\"\\n### Session: {session_id}\")\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "        )\n",
    "\n",
    "    # Convert single query to list\n",
    "    if isinstance(user_queries, str):\n",
    "        user_queries = [user_queries]\n",
    "\n",
    "    # Process each query\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nUser > {query}\")\n",
    "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "        # Stream agent response\n",
    "        async for event in runner_instance.run_async(\n",
    "            user_id=USER_ID, session_id=session.id, new_message=query_content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                text = event.content.parts[0].text\n",
    "                if text and text != \"None\":\n",
    "                    print(f\"Model: > {text}\")\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2737fb-89bb-4f99-a1ac-0dee2c38350b",
   "metadata": {},
   "source": [
    "### 1.5: Configure Retry Options\n",
    "\n",
    "When working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46e1d302-927c-4432-9ed9-4045eb846415",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5de4f-cfad-41d3-b089-3e9d04c6fa02",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ¤“ Section 2: Memory Workflow\n",
    "\n",
    "From the Introduction section, you now know why we need Memory. In order to integrate Memory into your Agents, there are **three high-level steps.**\n",
    "\n",
    "**Three-step integration process:**\n",
    "\n",
    "1. **Initialize** â†’ Create a `MemoryService` and provide it to your agent via the `Runner`\n",
    "2. **Ingest** â†’ Transfer session data to memory using `add_session_to_memory()`\n",
    "3. **Retrieve** â†’ Search stored memories using `search_memory()`\n",
    "\n",
    "Let's explore each step in the following sections.\n",
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-workflow.png\" width=\"1400\" alt=\"Memory workflow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee7c40b-473d-4339-b003-50a789a2a303",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ§  Section 3: Initialize MemoryService"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2edb2-094d-438e-ab5b-839ecd84ad5a",
   "metadata": {},
   "source": [
    "### 3.1 Initialize Memory\n",
    "\n",
    "ADK provides multiple `MemoryService` implementations through the `BaseMemoryService` interface:\n",
    "\n",
    "- **`InMemoryMemoryService`** - Built-in service for prototyping and testing (keyword matching, no persistence)\n",
    "- **`VertexAiMemoryBankService`** - Managed cloud service with LLM-powered consolidation and semantic search\n",
    "- **Custom implementations** - You can build your own using databases, though managed services are recommended\n",
    "\n",
    "For this notebook, we'll use `InMemoryMemoryService` to learn the core mechanics. The same methods work identically with production-ready services like Vertex AI Memory Bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ccd565e4-fd6a-4451-8a82-5a4d92b0da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_service = (\n",
    "    InMemoryMemoryService()\n",
    ")  # ADK's built-in Memory Service for development and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616eb56-ac5d-4818-a7cd-b65d81900de7",
   "metadata": {},
   "source": [
    "### 3.2 Add Memory to Agent\n",
    "\n",
    "Next, create a simple agent to answer user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "194cc7a9-f4b6-46be-b8ae-0093b264c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created\n"
     ]
    }
   ],
   "source": [
    "# Define constants used throughout the notebook\n",
    "APP_NAME = \"MemoryDemoApp\"\n",
    "USER_ID = \"demo_user\"\n",
    "\n",
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words.\",\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcb1ea-491e-420e-a119-cfa210e9c091",
   "metadata": {},
   "source": [
    "#### **Create Runner**\n",
    "\n",
    "Now provide both Session and Memory services to the `Runner`.\n",
    "\n",
    "**Key configuration:**\n",
    "\n",
    "The `Runner` requires both services to enable memory functionality:\n",
    "- **`session_service`** â†’ Manages conversation threads and events\n",
    "- **`memory_service`** â†’ Provides long-term knowledge storage\n",
    "\n",
    "Both services work together: Sessions capture conversations, Memory stores knowledge for retrieval across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e6659c1-1598-4322-b751-c69e93d17e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent and Runner created with memory support!\n"
     ]
    }
   ],
   "source": [
    "# Create Session Service\n",
    "session_service = InMemorySessionService()  # Handles conversations\n",
    "\n",
    "# Create runner with BOTH services\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=\"MemoryDemoApp\",\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,  # Memory service is now available!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent and Runner created with memory support!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc790b3-32a5-4904-8ff7-cbcd970649d2",
   "metadata": {},
   "source": [
    "### â€¼ï¸ Important\n",
    "\n",
    "**ðŸ’¡ Configuration vs. Usage:** Adding `memory_service` to the `Runner` makes memory *available* to your agent, but doesn't automatically use it. You must explicitly:\n",
    "1. **Ingest data** using `add_session_to_memory()` \n",
    "2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)\n",
    "\n",
    "Let's learn these steps next!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87263702-8dc8-4b14-a3c3-02f9b4ab07d9",
   "metadata": {},
   "source": [
    "### 3.3 MemoryService Implementation Options\n",
    "\n",
    "**This notebook: `InMemoryMemoryService`**\n",
    "- Stores raw conversation events without consolidation\n",
    "- Keyword-based search (simple word matching)\n",
    "- In-memory storage (resets on restart)\n",
    "- Ideal for learning and local development\n",
    "\n",
    "**Production: `VertexAiMemoryBankService` (You'll learn this on Day 5)**\n",
    "- LLM-powered extraction of key facts\n",
    "- Semantic search (meaning-based retrieval)\n",
    "- Persistent cloud storage\n",
    "- Integrates external knowledge sources\n",
    "\n",
    "**ðŸ’¡ API Consistency:** Both implementations use identical methods (`add_session_to_memory()`, `search_memory()`). The workflow you learn here applies to all memory services!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c9347-4c30-42f3-82ef-4a63c8d2db9f",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ’¾ Section 4: Ingest Session Data into Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef93f2-181e-428f-9048-d1ac9a5ca90a",
   "metadata": {},
   "source": [
    "**Why should you transfer Session data to Memory?**\n",
    "\n",
    "Now that memory is initialized, you need to populate it with knowledge. When you initialize a MemoryService, it starts completely empty. All your conversations are stored in Sessions, which contain raw events including every message, tool call, and metadata. To make this information available for long-term recall, you explicitly transfer it to memory using `add_session_to_memory()`.\n",
    "\n",
    "Here's where managed memory services like Vertex AI Memory Bank shine. **During transfer, they perform intelligent consolidation - extracting key facts while discarding conversational noise.** The `InMemoryMemoryService` we're using stores everything without consolidation, which is sufficient for learning the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded8ec3-36bb-4b7e-923c-01be26e75c1a",
   "metadata": {},
   "source": [
    "Before we can transfer anything, we need data. Let's have a conversation with our agent to populate the session. This conversation will be stored in the SessionService just like you learned in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2910d9ee-71b2-474a-950b-31c759961ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-01\n",
      "\n",
      "User > My favorite color is red-gold. Can you write a Haiku about it?\n",
      "Model: > A warm, rich color,\n",
      "Red and gold, a perfect blend,\n",
      "Shines with beauty bright.\n"
     ]
    }
   ],
   "source": [
    "# User tells agent about their favorite color\n",
    "await run_session(\n",
    "    runner,\n",
    "    \"My favorite color is red-gold. Can you write a Haiku about it?\",\n",
    "    \"conversation-01\",  # Session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9804e-1115-4870-9aa2-c6e54d169902",
   "metadata": {},
   "source": [
    "Let's verify the conversation was captured in the session. You should see the session events containing both the user's prompt and the model's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b55c558-1b20-45d0-9eb9-2a9f2e2b5d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Session contains:\n",
      "  user: My favorite color is red-gold. Can you write a Haiku about it?...\n",
      "  model: A warm, rich color,\n",
      "Red and gold, a perfect blend,\n",
      "Shines with beauty bright....\n"
     ]
    }
   ],
   "source": [
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
    ")\n",
    "\n",
    "# Let's see what's in the session\n",
    "print(\"ðŸ“ Session contains:\")\n",
    "for event in session.events:\n",
    "    text = (\n",
    "        event.content.parts[0].text[:77]\n",
    "        if event.content and event.content.parts\n",
    "        else \"(empty)\"\n",
    "    )\n",
    "    print(f\"  {event.content.role}: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62deaea-b719-4c90-9510-fa4b37bf931a",
   "metadata": {},
   "source": [
    "Perfect! The session contains our conversation. Now we're ready to transfer it to memory. Call `add_session_to_memory()` and pass the session object. This ingests the conversation into the memory store, making it available for future searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76abaa45-be37-4e46-a69c-ee2e44315b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session added to memory!\n"
     ]
    }
   ],
   "source": [
    "# This is the key method!\n",
    "await memory_service.add_session_to_memory(session)\n",
    "\n",
    "print(\"âœ… Session added to memory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd920a-ed02-498d-ba89-70243d7add47",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”Ž Section 5: Enable Memory Retrieval in Your Agent\n",
    "\n",
    "You've successfully transferred session data to memory, but there's one crucial step remaining. **Agents can't directly access the MemoryService - they need tools to search it.** \n",
    "\n",
    "This is by design: it gives you control over when and how memory is retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bec7c2-1220-41e2-b938-871523943ad3",
   "metadata": {},
   "source": [
    "### 5.1 Memory Retrieval in ADK\n",
    "\n",
    "ADK provides two built-in tools for memory retrieval:\n",
    "\n",
    "**`load_memory` (Reactive)**\n",
    "- Agent decides when to search memory\n",
    "- Only retrieves when the agent thinks it's needed\n",
    "- More efficient (saves tokens)\n",
    "- Risk: Agent might forget to search\n",
    "\n",
    "**`preload_memory` (Proactive)**\n",
    "- Automatically searches before every turn\n",
    "- Memory always available to the agent\n",
    "- Guaranteed context, but less efficient\n",
    "- Searches even when not needed\n",
    "\n",
    "Think of it like studying for an exam: `load_memory` is looking things up only when you need them, while `preload_memory` is reading all your notes before answering each question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998621d-dfa1-4358-9473-290187b3fc72",
   "metadata": {},
   "source": [
    "### 5.2 Add Load Memory Tool to Agent\n",
    "\n",
    "Let's start by implementing the reactive pattern. We'll recreate the agent from Section 3, this time adding the `load_memory` tool to its toolkit. Since this is a built-in ADK tool, you simply include it in the tools array without any custom implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49975615-f238-429e-a179-8f1aeef54238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with load_memory tool created.\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.\",\n",
    "    tools=[\n",
    "        load_memory\n",
    "    ],  # Agent now has access to Memory and can search it whenever it decides to!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent with load_memory tool created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec29ebe-ecb5-49f9-899d-4f61a40e07f5",
   "metadata": {},
   "source": [
    "### 5.3 Update the Runner and Test\n",
    "\n",
    "Let's now update the Runner to use our new `user_agent` that has the `load_memory` tool. And we'll ask the Agent about the favorite color which we had stored previously in another session.\n",
    "\n",
    "**ðŸ‘‰ Since sessions don't share conversation history, the only way the agent can answer correctly is by using the `load_memory` tool** to retrieve the information from long-term memory that we manually stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2569a689-3ba1-4c9f-b995-1632022055dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: color-test\n",
      "\n",
      "User > What is my favorite color?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: > Your favorite color is red-gold.\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "await run_session(runner, \"What is my favorite color?\", \"color-test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80594ccc-694c-459c-b468-ab07753cdfe5",
   "metadata": {},
   "source": [
    "### 5.4 Complete Manual Workflow Test\n",
    "\n",
    "Let's see the complete workflow in action. We'll have a conversation about a birthday, manually save it to memory, then test retrieval in a new session. This demonstrates the full cycle: **ingest â†’ store â†’ retrieve**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cbca885-5c08-4762-b609-fa20d88ab303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: birthday-session-01\n",
      "\n",
      "User > My birthday is on March 15th.\n",
      "Model: > I will remember that.\n"
     ]
    }
   ],
   "source": [
    "await run_session(runner, \"My birthday is on March 15th.\", \"birthday-session-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d229c99-306a-4775-bde0-01c5e1c7ab73",
   "metadata": {},
   "source": [
    "Now manually save this session to memory. This is the crucial step that transfers the conversation from short-term session storage to long-term memory storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e0e14ff8-5f3a-4046-ae9a-f097871a034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Birthday session saved to memory!\n"
     ]
    }
   ],
   "source": [
    "# Manually save the session to memory\n",
    "birthday_session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"birthday-session-01\"\n",
    ")\n",
    "\n",
    "await memory_service.add_session_to_memory(birthday_session)\n",
    "\n",
    "print(\"âœ… Birthday session saved to memory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ede89ec-663a-4ec6-9f99-dd7802d166db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: birthday-session-02\n",
      "\n",
      "User > When is my birthday?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: > Your birthday is on March 15th.\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval in a NEW session\n",
    "await run_session(\n",
    "    runner, \"When is my birthday?\", \"birthday-session-02\"  # Different session ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6ee0e-9eb0-4986-a6ec-48841fc3dee7",
   "metadata": {},
   "source": [
    "**What happens:**\n",
    "\n",
    "1. Agent receives: \"When is my birthday?\"\n",
    "2. Agent recognizes: This requires past conversation context\n",
    "3. Agent calls: `load_memory(\"birthday\")`\n",
    "4. Memory returns: Previous conversation containing \"March 15th\"\n",
    "5. Agent responds: \"Your birthday is on March 15th\"\n",
    "\n",
    "The memory retrieval worked even though this is a completely different session!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff09b9-d740-470e-b148-64f50c04a4a5",
   "metadata": {},
   "source": [
    "#### ðŸš€ Your Turn: Experiment with Both Patterns\n",
    "\n",
    "Try swapping `load_memory` with `preload_memory` by changing the tools array to `tools=[preload_memory]`.\n",
    "\n",
    "**What changes:**\n",
    "- `load_memory` (reactive): Agent decides when to search\n",
    "- `preload_memory` (proactive): Automatically loads memory before every turn\n",
    "\n",
    "**Test it:**\n",
    "1. Ask \"What is my favorite color?\" in a new session\n",
    "2. Ask \"Tell me a joke\" - notice that `preload_memory` still searches memory even though it's unnecessary\n",
    "3. Which pattern is better for different use cases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc998e-b40f-49cb-998d-19c2d90f5e57",
   "metadata": {},
   "source": [
    "### 5.5 Manual Memory Search\n",
    "\n",
    "Beyond agent tools, you can also search memories directly in your code. This is useful for:\n",
    "- Debugging memory contents\n",
    "- Building analytics dashboards  \n",
    "- Creating custom memory management UIs\n",
    "\n",
    "The `search_memory()` method takes a text query and returns a `SearchMemoryResponse` with matching memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "aa3d8cc5-6584-44ae-9063-1f616124d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Search Results:\n",
      "  Found 3 relevant memories\n",
      "\n",
      "  [user]: My favorite color is red-gold. Can you write a Haiku about it?...\n",
      "  [MemoryDemoAgent]: A warm, rich color,\n",
      "Red and gold, a perfect blend,\n",
      "Shines with beauty bright....\n",
      "  [user]: My birthday is on March 15th....\n"
     ]
    }
   ],
   "source": [
    "# Search for color preferences\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"What is the user's favorite color?\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57b80d-912f-4c9a-bc32-8f687878f208",
   "metadata": {},
   "source": [
    "#### **ðŸš€ Your Turn: Test Different Queries**\n",
    "\n",
    "Try these searches to understand how keyword matching works with `InMemoryMemoryService`:\n",
    "\n",
    "1. **\"what color does the user like\"**\n",
    "2. **\"haiku\"**\n",
    "3. **\"age\"**\n",
    "4. **\"preferred hue\"**\n",
    "\n",
    "Notice which queries return results and which don't. What pattern do you observe?\n",
    "\n",
    "**ðŸ’¡ Key Insight:** Memory search is grounded in reality - agents can't hallucinate memories that don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3628cd25-4c8c-4431-a3d3-cff807bda4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Search Results:\n",
      "  Found 1 relevant memories\n",
      "\n",
      "  [user]: My favorite color is red-gold. Can you write a Haiku about it?...\n"
     ]
    }
   ],
   "source": [
    "# Search for color preferences\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"haiku?\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f53004-06c0-431d-a974-af78e7d0deb4",
   "metadata": {},
   "source": [
    "### 5.6 How Search Works\n",
    "\n",
    "**InMemoryMemoryService (this notebook):**\n",
    "- **Method:** Keyword matching\n",
    "- **Example:** \"favorite color\" matches because those exact words exist\n",
    "- **Limitation:** \"preferred hue\" won't match\n",
    "\n",
    "**VertexAiMemoryBankService (Day 5):**\n",
    "- **Method:** Semantic search via embeddings\n",
    "- **Example:** \"preferred hue\" WILL match \"favorite color\"\n",
    "- **Advantage:** Understands meaning, not just keywords\n",
    "\n",
    "You'll explore semantic search in Day 5!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460e8ef-f184-4264-a4cb-99da6a92e40c",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ¤– Section 6: Automating Memory Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03d299-83b6-4ae9-b4fd-3fbc8de1fd6c",
   "metadata": {},
   "source": [
    "So far, we've **manually** called `add_session_to_memory()` to transfer data to long-term storage. Production systems need this to happen **automatically**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28d4750-55f9-46f2-a6d6-8899f7772495",
   "metadata": {},
   "source": [
    "### 6.1 Callbacks\n",
    "\n",
    "ADK's callback system lets you hook into key execution moments. Callbacks are **Python functions** you define and attach to agents - ADK automatically calls them at specific stages, acting like checkpoints during the agent's execution flow.\n",
    "\n",
    "**Think of callbacks as event listeners in your agent's lifecycle.** When an agent processes a request, it goes through multiple stages: receiving the input, calling the LLM, invoking tools, and generating the response. Callbacks let you insert custom logic at each of these stages without modifying the core agent code.\n",
    "\n",
    "**Available callback types:**\n",
    "\n",
    "- `before_agent_callback` â†’ Runs before agent starts processing a request\n",
    "- `after_agent_callback` â†’ Runs after agent completes its turn  \n",
    "- `before_tool_callback` / `after_tool_callback` â†’ Around tool invocations\n",
    "- `before_model_callback` / `after_model_callback` â†’ Around LLM calls\n",
    "- `on_model_error_callback` â†’ When errors occur\n",
    "\n",
    "**Common use cases:**\n",
    "\n",
    "- Logging and observability (track what the agent does)\n",
    "- Automatic data persistence (like saving to memory)\n",
    "- Custom validation or filtering\n",
    "- Performance monitoring\n",
    "\n",
    "**ðŸ“š Learn More:** [ADK Callbacks Documentation](https://google.github.io/adk-docs/agents/callbacks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93383ae-b62e-4e5a-937c-a8db2b939358",
   "metadata": {},
   "source": [
    "![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/types_of_callbacks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0134c6-6a6e-49b8-b024-1f741fbac80b",
   "metadata": {},
   "source": [
    "### 6.2 Automatic Memory Storage with Callbacks\n",
    "\n",
    "For automatic memory storage, we'll use `after_agent_callback`. This function triggers every time the agent finishes a turn, then calls `add_session_to_memory()` to persist the conversation automatically.\n",
    "\n",
    "But here's the challenge: how does our callback function actually access the memory service and current session? That's where `callback_context` comes in.\n",
    "\n",
    "When you define a callback function, ADK automatically passes a special parameter called `callback_context` to it. The `callback_context` provides access to the Memory Service and other runtime components.\n",
    "\n",
    "**How we'll use it:** In our callback, we'll access the memory service and current session to automatically save conversation data after each turn.\n",
    "\n",
    "**ðŸ’¡ Important:** You don't create this context - ADK creates it and passes it to your callback automatically when the callback runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b3bc33a1-7cbd-4a31-8b22-8ea8e6c43fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Callback created.\n"
     ]
    }
   ],
   "source": [
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Callback created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d1d7b7-4617-41f0-a6c1-4fb1eca72a99",
   "metadata": {},
   "source": [
    "### 6.3 Create an Agent: Callback and PreLoad Memory Tool\n",
    "\n",
    "Now create an agent that combines:\n",
    "- **Automatic storage:** `after_agent_callback` saves conversations\n",
    "- **Automatic retrieval:** `preload_memory` loads memories\n",
    "\n",
    "This creates a fully automated memory system with zero manual intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1ffcbfc3-eb77-405b-9be5-b45f1a99698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent created with automatic memory saving!\n"
     ]
    }
   ],
   "source": [
    "# Agent with automatic memory saving\n",
    "auto_memory_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"AutoMemoryAgent\",\n",
    "    instruction=\"Answer user questions.\",\n",
    "    tools=[preload_memory],\n",
    "    after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent created with automatic memory saving!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9e721-cc78-4eff-b612-277d6ffb07eb",
   "metadata": {},
   "source": [
    "**What happens automatically:**\n",
    "\n",
    "- After every agent response â†’ callback triggers\n",
    "- Session data â†’ transferred to memory\n",
    "- No manual `add_session_to_memory()` calls needed\n",
    "\n",
    "The framework handles everything!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7263cc2-2f69-44b5-a79a-1272b8d4bf64",
   "metadata": {},
   "source": [
    "### 6.4 Create a Runner and Test The Agent\n",
    "\n",
    "Time to test! Create a Runner with the auto-memory agent, connecting the session and memory services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5f281d05-9ce6-47dc-99fc-6c597294fb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created.\n"
     ]
    }
   ],
   "source": [
    "# Create a runner for the auto-save agent\n",
    "# This connects our automated agent to the session and memory services\n",
    "auto_runner = Runner(\n",
    "    agent=auto_memory_agent,  # Use the agent with callback + preload_memory\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,  # Same services from Section 3\n",
    "    memory_service=memory_service,\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7a5f5fae-a2cd-4870-ad53-9f34f3dc3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test\n",
      "\n",
      "User > I gifted a new toy to my nephew on his 1st birthday!\n",
      "Model: > That's wonderful! A first birthday is such a special milestone. I hope your nephew enjoys his new toy!\n",
      "\n",
      "### Session: auto-save-test-2\n",
      "\n",
      "User > What did I gift my nephew?\n",
      "Model: > You gifted your nephew a new toy on his 1st birthday.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Tell the agent about a gift (first conversation)\n",
    "# The callback will automatically save this to memory when the turn completes\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"I gifted a new toy to my nephew on his 1st birthday!\",\n",
    "    \"auto-save-test\",\n",
    ")\n",
    "\n",
    "# Test 2: Ask about the gift in a NEW session (second conversation)\n",
    "# The agent should retrieve the memory using preload_memory and answer correctly\n",
    "await run_session(\n",
    "    auto_runner,\n",
    "    \"What did I gift my nephew?\",\n",
    "    \"auto-save-test-2\",  # Different session ID - proves memory works across sessions!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b8d5c-c18f-4b7b-839e-8ff81f505d16",
   "metadata": {},
   "source": [
    "**What just happened:**\n",
    "\n",
    "1. **First conversation:** Mentioned gift to nephew\n",
    "   - Callback automatically saved to memory âœ…\n",
    "2. **Second conversation (new session):** Asked about the gift  \n",
    "   - `preload_memory` automatically retrieved the memory âœ…\n",
    "   - Agent answered correctly âœ…\n",
    "\n",
    "**Zero manual memory calls!** This is automated memory management in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f288db-074b-4ec7-ac2d-62a5f33f1cd3",
   "metadata": {},
   "source": [
    "### 6.5 How often should you save Sessions to Memory?\n",
    "\n",
    "**Options:**\n",
    "\n",
    "| Timing | Implementation | Best For |\n",
    "|--------|----------------|----------|\n",
    "| **After every turn** | `after_agent_callback` | Real-time memory updates |\n",
    "| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |\n",
    "| **Periodic intervals** | Timer-based background job | Long-running conversations |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9a209-b3b9-4a4c-8a76-202198c023bc",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ§© Section 7: Memory Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14d839-778b-4738-96d4-0fa3aa15de9a",
   "metadata": {},
   "source": [
    "### 7.1 The Limitation of Raw Storage\n",
    "\n",
    "**What we've stored so far:**\n",
    "- Every user message\n",
    "- Every agent response  \n",
    "- Every tool call\n",
    "\n",
    "**The problem:**\n",
    "```\n",
    "Session: 50 messages = 10,000 tokens\n",
    "Memory:  All 50 messages stored\n",
    "Search:  Returns all 50 messages â†’ Agent must process 10,000 tokens\n",
    "```\n",
    "\n",
    "This doesn't scale. We need **consolidation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6e5f6-64d8-45f4-bfa3-59ee4caf5a1f",
   "metadata": {},
   "source": [
    "### 7.2 What is Memory Consolidation?\n",
    "\n",
    "**Memory Consolidation** = Extracting **only important facts** while discarding conversational noise.\n",
    "\n",
    "**Before (Raw Storage):**\n",
    "\n",
    "```\n",
    "User: \"My favorite color is BlueGreen. I also like purple. \n",
    "       Actually, I prefer BlueGreen most of the time.\"\n",
    "Agent: \"Great! I'll remember that.\"\n",
    "User: \"Thanks!\"\n",
    "Agent: \"You're welcome!\"\n",
    "\n",
    "â†’ Stores ALL 4 messages (redundant, verbose)\n",
    "```\n",
    "\n",
    "**After (Consolidation):**\n",
    "\n",
    "```\n",
    "Extracted Memory: \"User's favorite color: BlueGreen\"\n",
    "\n",
    "â†’ Stores 1 concise fact\n",
    "```\n",
    "\n",
    "**Benefits:** Less storage, faster retrieval, more accurate answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9eda57-c457-4c62-b30a-a46b1831354d",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-consolidation.png\" width=\"1400\" alt=\"Memory consolidation\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f27a70-d6e4-41cd-b3a1-9cdb9efdf9f1",
   "metadata": {},
   "source": [
    "### 7.3 How Consolidation Works (Conceptual)\n",
    "\n",
    "**The pipeline:**\n",
    "\n",
    "```\n",
    "1. Raw Session Events\n",
    "   â†“\n",
    "2. LLM analyzes conversation\n",
    "   â†“\n",
    "3. Extracts key facts\n",
    "   â†“\n",
    "4. Stores concise memories\n",
    "   â†“\n",
    "5. Merges with existing memories (deduplication)\n",
    "```\n",
    "\n",
    "**Example transformation:**\n",
    "\n",
    "```\n",
    "Input:  \"I'm allergic to peanuts. I can't eat anything with nuts.\"\n",
    "\n",
    "Output: Memory {\n",
    "  allergy: \"peanuts, tree nuts\"\n",
    "  severity: \"avoid completely\"\n",
    "}\n",
    "```\n",
    "\n",
    "Natural language â†’ Structured, actionable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498739b-618f-4754-87ee-55d57699209d",
   "metadata": {},
   "source": [
    "### 7.4 Next Steps for Memory Consolidation\n",
    "\n",
    "**ðŸ’¡ Key Point:** Managed Memory Services handle consolidation **automatically**. \n",
    "\n",
    "**You use the same API:**\n",
    "- `add_session_to_memory()` â† Same method\n",
    "- `search_memory()` â† Same method\n",
    "\n",
    "**The difference:** What happens behind the scenes.\n",
    "- **InMemoryMemoryService:** Stores raw events\n",
    "- **VertexAiMemoryBankService:** Intelligently consolidates before storing\n",
    "\n",
    "**ðŸ“š Learn More:**\n",
    "- [Vertex AI Memory Bank: Memory Consolidation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories) -> You'll explore this in Day 5!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0030bb0-e938-408e-b72b-71532afa6941",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“Š Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da468a57-98f9-4dad-9203-b311f052ad46",
   "metadata": {},
   "source": [
    "You've learned the **core mechanics** of Memory in ADK:\n",
    "\n",
    "1. **âœ… Adding Memory**\n",
    "   - Initialize `MemoryService` alongside `SessionService`\n",
    "   - Both services are provided to the `Runner`\n",
    "\n",
    "2. **âœ… Storing Information**\n",
    "   - `await memory_service.add_session_to_memory(session)`\n",
    "   - Transfers session data to long-term storage\n",
    "   - Can be automated with callbacks\n",
    "\n",
    "3. **âœ… Searching Memory**\n",
    "   - `await memory_service.search_memory(app_name, user_id, query)`\n",
    "   - Returns relevant memories from past conversations\n",
    "\n",
    "4. **âœ… Retrieving in Agents**\n",
    "   - **Reactive:** `load_memory` tool (agent decides when to use memory)\n",
    "   - **Proactive:** `preload_memory` tool (always loads memory into LLM's system instructions)\n",
    "\n",
    "5. **âœ… Memory Consolidation**\n",
    "   - Extracts key information from Session data\n",
    "   - Provided by managed memory services such as Vertex AI Memory Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9e21f-7c9c-4eb3-8d8b-5d2b4b8e2e34",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ **Congratulations!** You've learned Memory Management in ADK!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46083d0e-dfcb-4ed0-9425-104a3660fc62",
   "metadata": {},
   "source": [
    "**ðŸ“š Learn More:**\n",
    "- [ADK Memory Documentation](https://google.github.io/adk-docs/sessions/memory/)\n",
    "- [Vertex AI Memory Bank](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/overview)\n",
    "- [Memory Consolidation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories)\n",
    "\n",
    "**ðŸŽ¯ Next Steps:**\n",
    "\n",
    "Ready for Day 4? Learn how to **implement Observability and Evaluate your agents** to ensure they're working as intended in production!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e450af-6a3e-4883-9814-94040da6372a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Authors\n",
    "\n",
    "| Authors |\n",
    "| --- |\n",
    "| [Sampath M](https://www.linkedin.com/in/msampathkumar/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951f798-01ad-465b-9313-fcaee887fa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
