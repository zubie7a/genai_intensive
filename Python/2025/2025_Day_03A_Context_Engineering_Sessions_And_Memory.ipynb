{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b8750b-ee7c-4fbb-8ea3-d1eb28fc224b",
   "metadata": {},
   "source": [
    "# üöÄ Memory Management - Part 1 - Sessions\n",
    "\n",
    "**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "\n",
    "- ‚úÖ What sessions are and how to use them in your agent\n",
    "- ‚úÖ How to build *stateful* agents with sessions and events\n",
    "- ‚úÖ How to persist sessions in a database\n",
    "- ‚úÖ Context management practices such as context compaction\n",
    "- ‚úÖ Best practices for sharing session State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "08776359-66c3-4923-a845-825eb3d6c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.apps.app import App, EventsCompactionConfig\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a5571fd4-1ee6-4895-b72f-d64d26defd9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loads variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2b8bcb02-8a02-49a3-8035-6abdb2e5783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"Environment variable GOOGLE_API_KEY not found!\")\n",
    "\n",
    "print(\"Secret loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87a09da8-16bc-4a7a-b1d9-172813847ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(\"‚úÖ Gemini API key setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7689cce2-daa7-4399-ab5f-29580b68ff6a",
   "metadata": {},
   "source": [
    "### 1.4: Helper functions\n",
    "\n",
    "Helper function that manages a complete conversation session, handling session\n",
    "creation/retrieval, query processing, and response streaming. It supports\n",
    "both single queries and multiple queries in sequence.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    ">>> await run_session(runner, \"What is the capital of France?\", \"geography-session\")\n",
    ">>> await run_session(runner, [\"Hello!\", \"What's my name?\"], \"user-intro-session\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8cc807fd-6e03-4d7b-b51a-062e24e5373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define helper functions that will be reused throughout the notebook\n",
    "async def run_session(\n",
    "    runner_instance: Runner,\n",
    "    user_queries: list[str] | str = None,\n",
    "    session_name: str = \"default\",\n",
    "):\n",
    "    print(f\"\\n ### Session: {session_name}\")\n",
    "\n",
    "    # Get app name from the Runner\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    # Attempt to create a new session or retrieve an existing one\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "\n",
    "    # Process queries if provided\n",
    "    if user_queries:\n",
    "        # Convert single query to list for uniform processing\n",
    "        if type(user_queries) == str:\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        # Process each query in the list sequentially\n",
    "        for query in user_queries:\n",
    "            print(f\"\\nUser > {query}\")\n",
    "\n",
    "            # Convert the query string to the ADK Content format\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            # Stream the agent's response asynchronously\n",
    "            async for event in runner_instance.run_async(\n",
    "                user_id=USER_ID, session_id=session.id, new_message=query\n",
    "            ):\n",
    "                # Check if the event contains valid content\n",
    "                if event.content and event.content.parts:\n",
    "                    # Filter out empty or \"None\" responses before printing\n",
    "                    if (\n",
    "                        event.content.parts[0].text != \"None\"\n",
    "                        and event.content.parts[0].text\n",
    "                    ):\n",
    "                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n",
    "    else:\n",
    "        print(\"No queries!\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f909443b-fe4c-4802-b6b6-d358664d7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e477c35-2f08-48e4-819d-cdb209145bce",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§π Section 2: Session Management\n",
    "\n",
    "### 2.1 The Problem\n",
    "\n",
    "At their core, Large Language Models are **inherently stateless**. Their awareness is confined to the information you provide in a single API call. This means an agent without proper context management will react to the current prompt without considering any previous history.\n",
    "\n",
    "**‚ùì Why does this matter?** Imagine trying to have a meaningful conversation with someone who forgets everything you've said after each sentence. That's the challenge we face with raw LLMs!\n",
    "\n",
    "In ADK, we use `Sessions` for **short term memory management** and `Memory` for **long term memory.** In the next notebook, you'll focus on `Memory`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80350fc9-845e-4323-a81b-6c73ad7b9d49",
   "metadata": {},
   "source": [
    "### 2.2 What is a Session?\n",
    "\n",
    "#### **üì¶ Session**\n",
    "\n",
    "A session is a container for conversations. It encapsulates the conversation history in a chronological manner and also records all tool interactions and responses for a **single, continuous conversation**. A session is tied to a user and agent; it is not shared with other users. Similarly, a session history for an Agent is not shared with other Agents.\n",
    "\n",
    "In ADK, a **Session** is comprised of two key components `Events` and `State`:\n",
    "\n",
    "**üìù Session.Events**:\n",
    "\n",
    "> While a session is a container for conversations, `Events` are the building blocks of a conversation.\n",
    ">\n",
    "> Example of Events:\n",
    "> - *User Input*: A message from the user (text, audio, image, etc.)\n",
    "> - *Agent Response*: The agent's reply to the user\n",
    "> - *Tool Call*: The agent's decision to use an external tool or API\n",
    "> - *Tool Output*: The data returned from a tool call, which the agent uses to continue its reasoning\n",
    "    \n",
    "\n",
    "**{} Session.State**:\n",
    "\n",
    "> `session.state` is the Agent's scratchpad, where it stores and updates dynamic details needed during the conversation. Think of it as a global `{key, value}` pair storage which is available to all subagents and tools.\n",
    "\n",
    "```\n",
    "graph TD\n",
    "    subgraph A[\"Agentic Application\"];\n",
    "        subgraph U[\"User\"]\n",
    "            subgraph S1[\"Session\"]\n",
    "                D1[\"Session.Events\"]\n",
    "                D2[\"Session.State\"]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "```\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/session-state-and-events.png\" width=\"320\" alt=\"Session state and events\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead1a81-3024-4a2c-9544-56c1d5368b6a",
   "metadata": {},
   "source": [
    "### 2.3 How to manage sessions?\n",
    "\n",
    "An agentic application can have multiple users and each user may have multiple sessions with the application.\n",
    "To manage these sessions and events, ADK offers a **Session Manager** and **Runner**.\n",
    "\n",
    "1. **`SessionService`**: The storage layer\n",
    "   - Manages creation, storage, and retrieval of session data\n",
    "   - Different implementations for different needs (memory, database, cloud)\n",
    "\n",
    "2. **`Runner`**: The orchestration layer\n",
    "   - Manages the flow of information between user and agent\n",
    "   - Automatically maintains conversation history\n",
    "   - Handles the Context Engineering behind the scenes\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "- **Session** = A notebook üìì\n",
    "- **Events** = Individual entries in a single page üìù\n",
    "- **SessionService** = The filing cabinet storing notebooks üóÑÔ∏è\n",
    "- **Runner** = The assistant managing the conversation ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1111c4-2d69-469b-bd9c-c96cf4044160",
   "metadata": {},
   "source": [
    "### 2.4 Implementing Our First Stateful Agent\n",
    "\n",
    "Let's build our first stateful agent, that can remember and have constructive conversations. \n",
    "\n",
    "ADK offers different types of sessions suitable for different needs. As a start, we'll start with a simple Session Management option (`InMemorySessionService`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "705e7ec0-147e-42e5-ad0d-8e899d7edc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stateful agent initialized!\n",
      "   - Application: default\n",
      "   - User: default\n",
      "   - Using: InMemorySessionService\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"default\"  # Application\n",
    "USER_ID = \"default\"  # User\n",
    "SESSION = \"default\"  # Session\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "\n",
    "# Step 1: Create the LLM Agent\n",
    "root_agent = Agent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"A text chatbot\",  # Description of the agent's purpose\n",
    ")\n",
    "\n",
    "# Step 2: Set up Session Management\n",
    "# InMemorySessionService stores conversations in RAM (temporary)\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Step 3: Create the Runner\n",
    "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "print(\"‚úÖ Stateful agent initialized!\")\n",
    "print(f\"   - Application: {APP_NAME}\")\n",
    "print(f\"   - User: {USER_ID}\")\n",
    "print(f\"   - Using: {session_service.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f864e1e-6268-4a06-9409-ca8dfe118525",
   "metadata": {},
   "source": [
    "### 2.5 Testing Our Stateful Agent\n",
    "\n",
    "Now let's see the magic of sessions in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e76def3-2189-4435-bd29-65283135a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: stateful-agentic-session\n",
      "\n",
      "User > Hi, I am Santiago! What is the capital of United States?\n",
      "gemini-2.5-flash-lite >  Hi Santiago! The capital of the United States is Washington, D.C.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  You mentioned that your name is Santiago.\n"
     ]
    }
   ],
   "source": [
    "# Run a conversation with two queries in the same session\n",
    "# Notice: Both queries are part of the SAME session, so context is maintained\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\n",
    "        \"Hi, I am Santiago! What is the capital of United States?\",\n",
    "        \"Hello! What is my name?\",  # This time, the agent should remember!\n",
    "    ],\n",
    "    \"stateful-agentic-session\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ee625-05b5-408c-87fc-cc29b583085b",
   "metadata": {},
   "source": [
    "üéâ **Success!** The agent remembered your name because both queries were part of the same session. The Runner automatically maintained the conversation history.\n",
    "\n",
    "But there's a catch: `InMemorySessionService` is temporary. **Once the application stops, all conversation history is lost.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e51cde-82c7-48fa-8b8a-a12f1353f0d5",
   "metadata": {},
   "source": [
    "### üõë (Optional) 2.6 Testing Agent's forgetfulness\n",
    "\n",
    "> To verify that the agent forgets the conversation, **restart the kernel**. Then, **run ALL the previous cells in this notebook EXCEPT the `run_session` in 2.5.**\n",
    "> \n",
    "> Now run the cell below. You'll see that the agent doesn't remember anything from the previous conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d15197de-0083-4b03-a1ce-6b8b5aaf623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: stateful-agentic-session\n",
      "\n",
      "User > What did I ask you about earlier?\n",
      "gemini-2.5-flash-lite >  You asked me about the capital of the United States.\n",
      "\n",
      "User > And remind me, what's my name?\n",
      "gemini-2.5-flash-lite >  Your name is Santiago.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell after restarting the kernel. All this history will be gone...\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\"What did I ask you about earlier?\", \"And remind me, what's my name?\"],\n",
    "    \"stateful-agentic-session\",\n",
    ")  # Note, we are using same session name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0f4d-7118-4bd5-8f09-612d70d8bfd8",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "Session information is not persistent (i.e., meaningful conversations are lost). While this is advantageous in testing environments, **in the real world, a user should be able to refer from past and resume conversations.** To achieve this, we must persist information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba5ae88-d9b5-4137-a8a6-246f2bec7212",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Section 3: Persistent Sessions with `DatabaseSessionService`\n",
    "\n",
    "While `InMemorySessionService` is great for prototyping, real-world applications need conversations to survive restarts, crashes, and deployments. Let's level up to persistent storage!\n",
    "\n",
    "### 3.1 Choosing the Right SessionService\n",
    "\n",
    "ADK provides different SessionService implementations for different needs:\n",
    "\n",
    "| Service | Use Case | Persistence | Best For |\n",
    "|---------|----------|-------------|----------|\n",
    "| **InMemorySessionService** | Development & Testing | ‚ùå Lost on restart | Quick prototypes |\n",
    "| **DatabaseSessionService** | Self-managed apps | ‚úÖ Survives restarts | Small to medium apps |\n",
    "| **Agent Engine Sessions** | Production on GCP | ‚úÖ Fully managed | Enterprise scale |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851e9cf-8c26-4c43-ac9e-8eded6471cc9",
   "metadata": {},
   "source": [
    "### 3.2 Implementing Persistent Sessions\n",
    "\n",
    "Let's upgrade to `DatabaseSessionService` using SQLite. This gives us persistence without needing a separate database server for this demo.\n",
    "\n",
    "Let's create a `chatbot_agent` capable of having a conversation with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "196b3179-c01b-4512-bea2-7859c0b2755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Upgraded to persistent sessions!\n",
      "   - Database: my_agent_data.db\n",
      "   - Sessions will survive restarts!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the same agent (notice we use LlmAgent this time)\n",
    "chatbot_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"A text chatbot with persistent memory\",\n",
    ")\n",
    "\n",
    "# Step 2: Switch to DatabaseSessionService\n",
    "# SQLite database will be created automatically\n",
    "db_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\n",
    "session_service = DatabaseSessionService(db_url=db_url)\n",
    "\n",
    "# Step 3: Create a new runner with persistent storage\n",
    "runner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "print(\"‚úÖ Upgraded to persistent sessions!\")\n",
    "print(f\"   - Database: my_agent_data.db\")\n",
    "print(f\"   - Sessions will survive restarts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00421469-16d2-42aa-adf4-885499961ef3",
   "metadata": {},
   "source": [
    "### 3.3 Test Run 1: Verifying Persistence\n",
    "\n",
    "In this first test run, we'll start a new conversation with the session ID `test-db-session-01`. We will first introduce our name as 'Sam' and then ask a question. In th\n",
    "e second turn, we will ask the agent for our name.\n",
    "\n",
    "Since we are using `DatabaseSessionService`, the agent should remember the name.\n",
    "\n",
    "After the conversation, we'll inspect the `my_agent_data.db` SQLite database directly to see how the conversation `events` (the user queries and model responses) are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bdb8b71-9da5-4221-bbaa-cfba72bac57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-01\n",
      "\n",
      "User > Hi, I am Sam! What is the capital of the United States?\n",
      "gemini-2.5-flash-lite >  Hello Sam! The capital of the United States is Washington, D.C.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  Your name is Sam.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner,\n",
    "    [\"Hi, I am Sam! What is the capital of the United States?\", \"Hello! What is my name?\"],\n",
    "    \"test-db-session-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc2411-ab5d-4371-9270-759156891c69",
   "metadata": {},
   "source": [
    "### üõë (Optional) 3.4 Test Run 2: Resuming a Conversation\n",
    "\n",
    "> ‚ÄºÔ∏è Now, let's repeat the test again, but this time, **let's stop this Kaggle Notebook's kernel and restart it again.**\n",
    ">\n",
    "> 1. Run all the previous cells in the notebook, **EXCEPT** the previous Section 3.3 (`run_session` cell).\n",
    ">\n",
    "> 2. Now, run the below cell with the **same session ID** (`test-db-session-01`).\n",
    "\n",
    "We will ask a new question and then ask for our name again. **Because the session is loaded from the database, the agent should still remember** that our name is 'Sam' from the first test run. This demonstrates the power of persistent sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "367d449e-b8be-41da-bf4c-570c9e0d87eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-01\n",
      "\n",
      "User > What is the capital of India?\n",
      "gemini-2.5-flash-lite >  The capital of India is New Delhi.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  Your name is Sam.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner,\n",
    "    [\"What is the capital of India?\", \"Hello! What is my name?\"],\n",
    "    \"test-db-session-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69efc1c5-790b-4f72-9319-ad67074b7f9a",
   "metadata": {},
   "source": [
    "### 3.5 Let's verify that the session data is isolated\n",
    "\n",
    "As mentioned earlier, a session is private conversation between an Agent and a User (i.e., two sessions do not share information). Let's run our `run_session` with a different session name `test-db-session-02` to confirm this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee0e24a0-26f2-42ac-a0d0-2b5e974907b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-02\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  I do not have access to your personal information, so I do not know your name.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner, [\"Hello! What is my name?\"], \"test-db-session-02\"\n",
    ")  # Note, we are using new session name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083a083-ddee-4e49-99ff-516cd1899425",
   "metadata": {},
   "source": [
    "### 3.6 How are the events stored in the Database?\n",
    "\n",
    "Since we are using a sqlite DB to store information, let's have a quick peek to see how information is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a730f5c1-ea69-4c7e-856a-17707e997312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app_name', 'session_id', 'author', 'content']\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hi, I am Sam! What is the capital of the United States?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Hello Sam! The capital of the United States is Washington, D.C.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Sam.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"What is the capital of India?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"The capital of India is New Delhi.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Sam.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-02', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-02', 'text_chat_bot', '{\"parts\": [{\"text\": \"I do not have access to your personal information, so I do not know your name.\"}], \"role\": \"model\"}')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def check_data_in_db():\n",
    "    with sqlite3.connect(\"my_agent_data.db\") as connection:\n",
    "        cursor = connection.cursor()\n",
    "        result = cursor.execute(\n",
    "            \"select app_name, session_id, author, content from events\"\n",
    "        )\n",
    "        print([_[0] for _ in result.description])\n",
    "        for each in result.fetchall():\n",
    "            print(each)\n",
    "\n",
    "\n",
    "check_data_in_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eead8d-3607-4673-8c40-59d47d6d92de",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚è≥ Section 4: Context Compaction\n",
    "\n",
    "As you can see, all the events are stored in full in the session Database, and this quickly adds up. For a long, complex task, this list of events can become very large, leading to slower performance and higher costs.\n",
    "\n",
    "But what if we could automatically summarize the past? Let's use ADK's **Context Compaction** feature to see **how to automatically reduce the context that's stored in the Session.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b9fbd-849d-4688-b926-d5fd02a22c51",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/context-compaction.png\" width=\"1400\" alt=\"Context compaction\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708cba7-1166-4d6f-b4ed-696d99594d43",
   "metadata": {},
   "source": [
    "### 4.1 Create an App for the agent\n",
    "\n",
    "To enable this feature, let's use the same `chatbot_agent` we created in Section 3.2. \n",
    "\n",
    "The first step is to create an object called `App`. We'll give it a name and pass in our chatbot_agent. \n",
    "\n",
    "We'll also create a new config to do the Context Compaction. This **`EventsCompactionConfig`** defines two key variables:\n",
    "\n",
    "- **compaction_interval**: Asks the Runner to compact the history after every `n` conversations\n",
    "- **overlap_size**: Defines the number of previous conversations to retain for overlap\n",
    "\n",
    "We'll then provide this app to the Runner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "162312f1-fbd4-4c0d-9ee3-167ec47827ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research App upgraded with Events Compaction!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/11/43wjw06j1hsbn86xkwt5vt4m0000gn/T/ipykernel_80697/3773147741.py:6: UserWarning: [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  events_compaction_config=EventsCompactionConfig(\n"
     ]
    }
   ],
   "source": [
    "# Re-define our app with Events Compaction enabled\n",
    "research_app_compacting = App(\n",
    "    name=\"research_app_compacting\",\n",
    "    root_agent=chatbot_agent,\n",
    "    # This is the new part!\n",
    "    events_compaction_config=EventsCompactionConfig(\n",
    "        compaction_interval=3,  # Trigger compaction every 3 invocations\n",
    "        overlap_size=1,  # Keep 1 previous turn for context\n",
    "    ),\n",
    ")\n",
    "\n",
    "db_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\n",
    "session_service = DatabaseSessionService(db_url=db_url)\n",
    "\n",
    "# Create a new runner for our upgraded app\n",
    "research_runner_compacting = Runner(\n",
    "    app=research_app_compacting, session_service=session_service\n",
    ")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Research App upgraded with Events Compaction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c19269-c6f5-4072-bc5d-061165133aab",
   "metadata": {},
   "source": [
    "### 4.2 Running the Demo\n",
    "\n",
    "Now, let's have a conversation that is long enough to trigger the compaction. When you run the cell below, the output will look like a normal conversation. However, because we configured our `App`, a compaction process will run silently in the background after the 3rd invocation.\n",
    "\n",
    "In the next step, we'll prove that it happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4394cbda-93d6-4283-90f5-4f48fd9c2a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > What is the latest news about AI in healthcare?\n",
      "gemini-2.5-flash-lite >  The field of AI in healthcare is rapidly evolving, so \"latest\" can mean a lot of things! However, here are some of the most prominent and recent trends and developments:\n",
      "\n",
      "**1. AI for Drug Discovery and Development:**\n",
      "\n",
      "*   **Accelerated Discovery:** AI algorithms are becoming incredibly adept at identifying potential drug candidates and predicting their efficacy and safety. This significantly speeds up the traditionally lengthy and expensive drug discovery process.\n",
      "*   **Personalized Medicine:** AI is helping to analyze vast datasets of patient genetic information, medical history, and treatment responses to identify the most effective treatments for individual patients.\n",
      "*   **Repurposing Existing Drugs:** AI can identify new therapeutic uses for already approved drugs, offering a faster path to treatment for various diseases.\n",
      "\n",
      "**2. AI in Medical Imaging and Diagnostics:**\n",
      "\n",
      "*   **Enhanced Accuracy and Speed:** AI-powered tools are assisting radiologists and pathologists in analyzing medical images (X-rays, CT scans, MRIs, biopsies) with remarkable accuracy and speed, often detecting subtle anomalies that might be missed by the human eye.\n",
      "*   **Early Disease Detection:** AI is showing promise in detecting diseases like cancer, diabetic retinopathy, and cardiovascular conditions at their earliest, most treatable stages.\n",
      "*   **Workflow Optimization:** AI can help prioritize urgent cases, reduce reporting times, and improve the overall efficiency of diagnostic departments.\n",
      "\n",
      "**3. AI for Patient Care and Management:**\n",
      "\n",
      "*   **Predictive Analytics for Patient Deterioration:** AI models can predict which patients are at higher risk of deterioration, allowing healthcare providers to intervene proactively and prevent adverse events.\n",
      "*   **Virtual Assistants and Chatbots:** AI-powered chatbots are being used for patient triage, appointment scheduling, answering common medical questions, and providing support for chronic conditions.\n",
      "*   **Remote Patient Monitoring:** AI analyzes data from wearable devices and sensors to monitor patients at home, alerting clinicians to potential issues.\n",
      "*   **Administrative Task Automation:** AI is automating repetitive tasks like medical coding, billing, and documentation, freeing up healthcare professionals to focus on patient care.\n",
      "\n",
      "**4. AI in Clinical Decision Support:**\n",
      "\n",
      "*   **Evidence-Based Recommendations:** AI systems can sift through vast amounts of medical literature and research to provide clinicians with evidence-based recommendations for diagnosis and treatment.\n",
      "*   **Identifying Treatment Gaps:** AI can analyze patient data to identify potential gaps in care or areas where treatment protocols might not be optimally followed.\n",
      "\n",
      "**5. Ethical and Regulatory Considerations:**\n",
      "\n",
      "*   **Bias in AI:** A significant ongoing discussion revolves around ensuring AI algorithms are free from bias that could lead to disparities in care for certain patient populations.\n",
      "*   **Data Privacy and Security:** Robust measures are needed to protect sensitive patient data used by AI systems.\n",
      "*   **Regulatory Approval:** Regulatory bodies like the FDA are actively developing frameworks for the approval and oversight of AI-powered medical devices and software.\n",
      "\n",
      "**Examples of recent developments you might find in the news:**\n",
      "\n",
      "*   **Specific AI tools approved by regulatory bodies** for diagnostic purposes.\n",
      "*   **Clinical trial results** showcasing the effectiveness of AI in drug discovery or treatment.\n",
      "*   **Hospitals and healthcare systems** announcing the implementation of new AI technologies.\n",
      "*   **Research papers** detailing breakthroughs in AI algorithms for specific medical conditions.\n",
      "\n",
      "To get the *absolute latest*, I recommend checking reputable medical news sources, technology publications, and scientific journals. Some good starting points would be:\n",
      "\n",
      "*   **STAT News**\n",
      "*   **FierceHealthcare**\n",
      "*   **MedCity News**\n",
      "*   **Nature Medicine**\n",
      "*   **The Lancet Digital Health**\n",
      "*   **JAMA Network**\n",
      "*   **Google AI Blog (often features healthcare applications)**\n",
      "*   **Microsoft Healthcare Blog**\n",
      "\n",
      "Is there a specific area within AI in healthcare you're most interested in? Knowing that might help me provide more tailored information.\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Are there any new developments in drug discovery?\n",
      "gemini-2.5-flash-lite >  Yes, there are constant and exciting new developments in AI-driven drug discovery! It's one of the most dynamic areas where AI is making a significant impact. Here are some of the key recent trends and breakthroughs:\n",
      "\n",
      "**1. Generative AI for Molecule Design:**\n",
      "\n",
      "*   **De Novo Design:** This is a major area of progress. Instead of just screening existing compounds, generative AI models (like those used in image or text generation) are now being trained to *design entirely new molecules* from scratch. These molecules are optimized for specific properties, such as binding to a target protein or having favorable pharmacokinetic profiles.\n",
      "*   **Optimizing Properties:** Generative AI can create molecules that are not only effective but also have better solubility, reduced toxicity, and easier synthesis, speeding up the entire development pipeline.\n",
      "\n",
      "**2. Advanced Target Identification and Validation:**\n",
      "\n",
      "*   **Understanding Disease Mechanisms:** AI is being used to analyze complex biological data (genomics, proteomics, transcriptomics) to uncover novel disease pathways and identify previously unknown drug targets.\n",
      "*   **Predicting Target Druggability:** AI models can assess whether a particular target is likely to be \"druggable,\" meaning that a molecule can be designed to interact with it effectively.\n",
      "\n",
      "**3. Enhanced Screening and Prioritization:**\n",
      "\n",
      "*   **Virtual Screening at Scale:** AI can rapidly screen massive virtual libraries of compounds (billions of molecules) to identify those most likely to be effective against a target. This is far more efficient than traditional high-throughput screening.\n",
      "*   **Predicting Efficacy and Toxicity:** AI models are becoming increasingly sophisticated at predicting how well a compound will work and its potential side effects *before* it even enters preclinical testing.\n",
      "\n",
      "**4. Accelerating Preclinical and Clinical Trials:**\n",
      "\n",
      "*   **Biomarker Discovery:** AI can identify biomarkers that predict a patient's response to a drug, enabling more targeted clinical trials and personalized treatment strategies.\n",
      "*   **Trial Design Optimization:** AI can help optimize clinical trial design by identifying the most suitable patient populations, predicting trial outcomes, and even simulating trial scenarios.\n",
      "*   **Patient Stratification:** AI can analyze patient data to identify subgroups that are most likely to benefit from a particular drug, leading to more efficient and successful trials.\n",
      "\n",
      "**5. Novel AI Approaches:**\n",
      "\n",
      "*   **Graph Neural Networks (GNNs):** These are proving very effective for representing and learning from molecular structures, which are inherently graph-like.\n",
      "*   **Reinforcement Learning:** Used to iteratively improve molecule design by rewarding models for generating molecules with desired properties.\n",
      "*   **Natural Language Processing (NLP):** Applied to analyze scientific literature, patents, and clinical trial data to extract valuable insights for drug discovery.\n",
      "\n",
      "**Recent Examples and Buzzwords you might see:**\n",
      "\n",
      "*   **\"AI-designed drug enters human trials.\"** This is a major milestone that has been achieved and is becoming more common. Companies are announcing candidates discovered or designed with AI that are now being tested in humans.\n",
      "*   **\"Partnerships between AI drug discovery companies and big pharma.\"** Major pharmaceutical companies are increasingly collaborating with or acquiring AI-focused biotech firms to leverage their cutting-edge technologies.\n",
      "*   **\"New AI platforms launched for specific disease areas.\"** Companies are specializing their AI platforms for areas like oncology, infectious diseases, or neurological disorders.\n",
      "\n",
      "**Key Companies and Players to Watch:**\n",
      "\n",
      "Many companies are at the forefront of this revolution. Some prominent ones include:\n",
      "\n",
      "*   **Exscientia**\n",
      "*   **Recursion Pharmaceuticals**\n",
      "*   **BenevolentAI**\n",
      "*   **Atomwise**\n",
      "*   **Schr√∂dinger**\n",
      "*   **Insilico Medicine**\n",
      "*   **Relay Therapeutics**\n",
      "\n",
      "**Challenges Remain:**\n",
      "\n",
      "Despite the immense progress, challenges persist. These include:\n",
      "\n",
      "*   **Translational challenges:** Ensuring that AI-discovered drugs translate effectively from the lab to human patients.\n",
      "*   **Data quality and availability:** The performance of AI models is highly dependent on the quality and quantity of biological and chemical data.\n",
      "*   **Explainability:** Understanding *why* an AI model proposes a particular molecule or target can still be difficult.\n",
      "*   **Regulatory pathways:** Navigating the regulatory approval process for AI-discovered drugs is an evolving landscape.\n",
      "\n",
      "In summary, AI is fundamentally reshaping drug discovery by making it faster, more efficient, and capable of exploring chemical space in ways never before possible. The next few years are likely to see even more significant breakthroughs and the approval of AI-discovered drugs.\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Tell me more about the second development you found.\n",
      "gemini-2.5-flash-lite >  You're referring to the **second development I mentioned, which was \"AI for Medical Imaging and Diagnostics.\"**\n",
      "\n",
      "This area is incredibly active and has profound implications for how we detect and understand diseases. Here's a deeper dive:\n",
      "\n",
      "**Core Concept:**\n",
      "\n",
      "AI, particularly deep learning (a subset of machine learning), excels at pattern recognition. In medical imaging, it's trained on vast datasets of images (like X-rays, CT scans, MRIs, ultrasounds, and pathology slides) that have been labeled by expert radiologists or pathologists. By analyzing these labeled examples, the AI learns to identify subtle visual cues associated with various conditions.\n",
      "\n",
      "**Key Capabilities and Applications:**\n",
      "\n",
      "*   **Detection of Anomalies:**\n",
      "    *   **Cancer Screening:** AI is being used to flag suspicious lesions in mammograms (breast cancer), lung nodules in CT scans, and polyps in colonoscopies.\n",
      "    *   **Diabetic Retinopathy:** AI algorithms can detect early signs of this vision-threatening complication of diabetes by analyzing retinal images, often with higher accuracy and speed than human graders in some contexts.\n",
      "    *   **Cardiovascular Disease:** AI can analyze cardiac MRI or CT scans to detect signs of heart disease, assess cardiac function, and even predict future cardiovascular events.\n",
      "    *   **Neurological Conditions:** AI can help identify brain tumors, signs of stroke, or early indicators of neurodegenerative diseases like Alzheimer's from brain scans.\n",
      "\n",
      "*   **Quantification and Measurement:**\n",
      "    *   AI can automatically measure tumor size, volume, and growth over time, which is crucial for monitoring treatment response.\n",
      "    *   It can precisely measure organ volumes, blood flow, and other physiological parameters.\n",
      "\n",
      "*   **Classification and Diagnosis Assistance:**\n",
      "    *   Once an anomaly is detected, AI can help classify it (e.g., benign vs. malignant tumor).\n",
      "    *   It can assist pathologists in grading tumors based on cellular characteristics from digital pathology slides.\n",
      "\n",
      "*   **Image Enhancement and Reconstruction:**\n",
      "    *   AI can improve the quality of medical images, allowing for lower radiation doses in CT scans or faster MRI acquisition times.\n",
      "    *   It can reconstruct high-resolution images from lower-resolution data.\n",
      "\n",
      "*   **Workflow Optimization:**\n",
      "    *   **Triage:** AI can prioritize urgent cases in radiology queues, ensuring that critical findings are reviewed quickly.\n",
      "    *   **Reporting:** AI can help draft preliminary reports or extract key findings from images, saving radiologists time.\n",
      "    *   **Quality Control:** AI can flag images that might be of suboptimal quality for review.\n",
      "\n",
      "**Why is this so impactful?**\n",
      "\n",
      "*   **Improved Accuracy:** In some specific tasks, AI has demonstrated accuracy comparable to or even exceeding human experts, especially when dealing with large volumes of data or subtle patterns.\n",
      "*   **Increased Efficiency:** AI can process images much faster than humans, reducing turnaround times for diagnoses and allowing clinicians to see more patients.\n",
      "*   **Accessibility:** In resource-limited settings where there's a shortage of specialized radiologists or pathologists, AI can help bridge the gap by providing diagnostic support.\n",
      "*   **Early Detection:** By identifying subtle signs early, AI can lead to earlier interventions and better patient outcomes.\n",
      "\n",
      "**Recent Advancements and Trends:**\n",
      "\n",
      "*   **Federated Learning:** This technique allows AI models to be trained on data from multiple hospitals without the data ever leaving the institutions, addressing privacy concerns.\n",
      "*   **Multi-modal AI:** Combining imaging data with other patient information (electronic health records, genomics) for more comprehensive diagnoses.\n",
      "*   **Explainable AI (XAI):** Efforts are underway to make AI models more transparent, so clinicians can understand *why* the AI made a particular recommendation, building trust.\n",
      "*   **Regulatory Approvals:** A growing number of AI-powered medical imaging devices and software have received regulatory clearance (e.g., FDA approval), indicating their maturity and readiness for clinical adoption.\n",
      "\n",
      "**Challenges:**\n",
      "\n",
      "*   **Generalizability:** Ensuring AI models trained on one population or with one type of scanner work well across different demographics and equipment.\n",
      "*   **Bias:** AI models can inherit biases present in the training data, leading to disparities in performance for certain patient groups.\n",
      "*   **Integration into Clinical Workflow:** Seamlessly integrating AI tools into existing hospital systems and workflows is crucial for adoption.\n",
      "*   **Over-reliance and Deskilling:** Concerns exist about clinicians becoming too reliant on AI, potentially leading to a decline in their own diagnostic skills.\n",
      "\n",
      "Overall, AI in medical imaging is a field that is rapidly moving from research to widespread clinical application, promising to revolutionize how we diagnose and manage diseases.\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Who are the main companies involved in that?\n",
      "gemini-2.5-flash-lite >  You're asking about the companies involved in **AI for Medical Imaging and Diagnostics.** This is a diverse landscape, with contributions from both established players in the medical technology and imaging industry, as well as specialized AI startups.\n",
      "\n",
      "Here are some of the key companies, categorized by their primary role:\n",
      "\n",
      "**1. Major Imaging Equipment Manufacturers (Integrating AI into their platforms):**\n",
      "\n",
      "These companies are embedding AI capabilities directly into their imaging hardware and software solutions.\n",
      "\n",
      "*   **Siemens Healthineers:** A major player that is heavily investing in AI for various aspects of imaging, from image acquisition and reconstruction to analysis and workflow optimization. They have numerous AI-powered applications for different modalities.\n",
      "*   **GE Healthcare:** Similar to Siemens, GE Healthcare is integrating AI across its imaging portfolio, focusing on areas like cardiac imaging, oncology, and neurology to improve image quality, speed, and diagnostic insights.\n",
      "*   **Philips:** Philips is also incorporating AI into its imaging systems, aiming to enhance image quality, streamline workflows, and provide clinical decision support for radiologists.\n",
      "*   **Canon Medical Systems:** Actively developing and deploying AI solutions for their CT, MRI, and ultrasound systems, with a focus on improving diagnostic accuracy and workflow efficiency.\n",
      "*   **Hologic:** Known for its mammography and women's health imaging, Hologic is incorporating AI to improve the detection of breast cancer.\n",
      "\n",
      "**2. Specialized AI Startups & Software Providers (Focusing on AI-powered analysis):**\n",
      "\n",
      "These companies often develop AI algorithms that can be used with imaging equipment from various manufacturers. They are at the cutting edge of AI-specific applications.\n",
      "\n",
      "*   **Viz.ai:** Gained significant traction for its AI platform that analyzes CT scans to detect conditions like stroke and pulmonary embolism, rapidly alerting care teams. They have multiple FDA-cleared products.\n",
      "*   **Arterys:** Offers an AI platform that provides advanced image analysis for cardiology, oncology, and pulmonology, focusing on quantitative insights and clinical decision support.\n",
      "*   **Aidoc:** Develops AI solutions to prioritize and analyze medical images, flagging critical findings for radiologists to review, particularly for acute conditions like intracranial hemorrhage and pulmonary embolism.\n",
      "*   **Zebra Medical Vision (now part of Nanox):** Was a pioneer in AI for medical imaging, offering solutions for detecting various conditions from CT scans, including fatty liver, osteoporosis, and cardiovascular risks.\n",
      "*   **RadNet:** While primarily a radiology service provider, RadNet is also developing and deploying AI tools to enhance its own operations and improve diagnostic accuracy.\n",
      "*   **Klara:** Focuses on AI-powered diagnostic tools, particularly for radiology and pathology.\n",
      "*   **Subtle Medical:** Develops AI solutions to improve image quality and reduce scan times for MRI and PET scans, enabling higher throughput and better patient comfort.\n",
      "*   **Caption Health (now part of GE HealthCare):** Developed AI-guided ultrasound technology that helps less experienced sonographers acquire diagnostic-quality images.\n",
      "\n",
      "**3. Cloud Providers & Technology Giants (Enabling AI infrastructure and platforms):**\n",
      "\n",
      "While not directly developing diagnostic AI tools in most cases, these companies provide the crucial cloud infrastructure, AI development tools, and sometimes specialized healthcare AI platforms that enable others to build and deploy these solutions.\n",
      "\n",
      "*   **Google Cloud:** Offers AI and machine learning services that healthcare providers and developers can use to build and deploy AI solutions for medical imaging. They also conduct their own research in this area.\n",
      "*   **Amazon Web Services (AWS):** Provides a comprehensive suite of cloud computing and AI/ML services that are widely used by healthcare companies for developing and hosting AI applications.\n",
      "*   **Microsoft Azure:** Similar to Google and AWS, Azure offers AI tools and cloud infrastructure that facilitate the development and deployment of AI in healthcare, including medical imaging.\n",
      "\n",
      "**4. Pathology Focused AI Companies:**\n",
      "\n",
      "*   **Paige:** A leader in AI-powered digital pathology, developing tools to assist pathologists in diagnosing cancer from tissue slides. They have received FDA approval for some of their products.\n",
      "*   **Proscia:** Offers AI and data management solutions for digital pathology, aiming to improve diagnostic accuracy and efficiency.\n",
      "\n",
      "This list is not exhaustive, as the field is constantly evolving with new companies emerging and existing ones expanding their AI capabilities. The trend is towards deeper integration of AI across the entire imaging value chain, from acquisition to interpretation and reporting.\n"
     ]
    }
   ],
   "source": [
    "# Turn 1\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"What is the latest news about AI in healthcare?\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 2\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Are there any new developments in drug discovery?\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 3 - Compaction should trigger after this turn!\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Tell me more about the second development you found.\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 4\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Who are the main companies involved in that?\",\n",
    "    \"compaction_demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3061a6eb-8183-4c2d-8d75-d7f0de7f6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Searching for Compaction Summary Event ---\n",
      "\n",
      "‚úÖ SUCCESS! Found the Compaction Event:\n",
      "  Author: user\n",
      "\n",
      " Compacted information: model_version=None content=None grounding_metadata=None partial=None turn_complete=None finish_reason=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None live_session_resumption_update=None input_transcription=None output_transcription=None avg_logprobs=None logprobs_result=None cache_metadata=None citation_metadata=None invocation_id='f6f836fb-2e06-48ff-9611-db1d8857e861' author='user' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction={'start_timestamp': 1763105271.385597, 'end_timestamp': 1763105278.096233, 'compacted_content': {'parts': [{'video_metadata': None, 'thought': None, 'inline_data': None, 'file_data': None, 'thought_signature': None, 'code_execution_result': None, 'executable_code': None, 'function_call': None, 'function_response': None, 'text': 'The user inquired about the latest news in AI in healthcare. The AI agent provided a comprehensive overview of key trends, including AI for drug discovery, medical imaging and diagnostics, patient care, and clinical decision support, along with ethical considerations.\\n\\nThe user then specifically asked for more details on developments in drug discovery. The AI agent elaborated on this area, highlighting generative AI for molecule design (de novo design and property optimization), advanced target identification and validation, enhanced screening and prioritization, and acceleration of preclinical/clinical trials. It also mentioned novel AI approaches like Graph Neural Networks and Reinforcement Learning, along with recent examples, key companies, and remaining challenges.\\n\\nFinally, the user asked for more information on the second development mentioned in the initial response. The AI agent then provided a detailed explanation of **AI for Medical Imaging and Diagnostics**, covering its core concept, key capabilities and applications (detection of anomalies, quantification, classification, image enhancement, workflow optimization), impact, recent advancements (federated learning, multi-modal AI, XAI, regulatory approvals), and challenges.'}], 'role': 'model'}}, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None) long_running_tool_ids=set() branch=None id='1bd6fc10-6824-45f6-baac-8a8abafdd387' timestamp=1763105283.645979\n"
     ]
    }
   ],
   "source": [
    "# Get the final session state\n",
    "final_session = await session_service.get_session(\n",
    "    app_name=research_runner_compacting.app_name,\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"compaction_demo\",\n",
    ")\n",
    "\n",
    "print(\"--- Searching for Compaction Summary Event ---\")\n",
    "found_summary = False\n",
    "for event in final_session.events:\n",
    "    # Compaction events have a 'compaction' attribute\n",
    "    if event.actions and event.actions.compaction:\n",
    "        print(\"\\n‚úÖ SUCCESS! Found the Compaction Event:\")\n",
    "        print(f\"  Author: {event.author}\")\n",
    "        print(f\"\\n Compacted information: {event}\")\n",
    "        found_summary = True\n",
    "        break\n",
    "\n",
    "if not found_summary:\n",
    "    print(\n",
    "        \"\\n‚ùå No compaction event found. Try increasing the number of turns in the demo.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605572d2-3162-44fc-bf6b-825ed47c8cba",
   "metadata": {},
   "source": [
    "### 4.4 What you've accomplished: Automatic Context Management\n",
    "\n",
    "You just found the proof! The presence of that special summary `Event` in your session's history is the tangible result of the compaction process.\n",
    "\n",
    "**Let's recap what you just witnessed:**\n",
    "\n",
    "1.  **Silent Operation**: You ran a standard conversation, and from the outside, nothing seemed different.\n",
    "2.  **Background Compaction**: Because you configured the `App` with `EventsCompactionConfig`, the ADK `Runner` automatically monitored the conversation length. Once the threshold was met, it triggered the summarization process in the background.\n",
    "3.  **Verified Result**: By inspecting the session's events, you found the summary that the LLM generated. This summary now replaces the older, more verbose turns in the agent's active context.\n",
    "\n",
    "**For all future turns in this conversation, the agent will be given this concise summary instead of the full history.** This saves costs, improves performance, and helps the agent stay focused on what's most important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd204f-6a9f-41ec-9ed5-b818a27f7f00",
   "metadata": {},
   "source": [
    "### 4.5 More Context Engineering options in ADK\n",
    "\n",
    "#### üëâ Custom Compaction\n",
    "In this example, we used ADK's default summarizer. For more advanced use cases, you can provide your own by defining a custom `SlidingWindowCompactor` and passing it to the config. This allows you to control the summarization prompt or even use a different, specialized LLM for the task. You can read more about it in the [official documentation](https://google.github.io/adk-docs/context/compaction/).\n",
    "\n",
    "#### üëâ Context Caching\n",
    "ADK also provides **Context Caching** to help reduce the token size of the static instructions that are fed to the LLM by caching the request data. Read more about it [here](https://google.github.io/adk-docs/context/caching/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274168c-b01f-4bd8-872a-8e2b5726a816",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "While we can do Context Compaction and use a database to resume a session, we face new challenges now. In some cases, **we have key information or preferences that we want to share across other sessions.** \n",
    "\n",
    "In these scenarios, instead of sharing the entire session history, transferring information from a few key variables can improve the session experience. Let's see how to do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f433ff4-f0cf-4a04-9c00-2457132d1b80",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ù Section 5: Working with Session State\n",
    "\n",
    "### 5.1 Creating custom tools for Session state management\n",
    "\n",
    "Let's explore how to manually manage session state through custom tools. In this example, we'll identify a **transferable characteristic**, like a user's name and their country, and create tools to capture and save it.\n",
    "\n",
    "**Why This Example?**\n",
    "\n",
    "The username is a perfect example of information that:\n",
    "\n",
    "- Is introduced once but referenced multiple times\n",
    "- Should persist throughout a conversation\n",
    "- Represents a user-specific characteristic that enhances personalization\n",
    "\n",
    "Here, for demo purposes, we'll create two tools that can store and retrieve user name and country from the Session State. **Note that all tools have access to the `ToolContext` object.** You don't have to create separate tools for each piece of information you want to share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8acb635d-7103-486a-be8c-702fc8683e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools created.\n"
     ]
    }
   ],
   "source": [
    "# Define scope levels for state keys (following best practices)\n",
    "USER_NAME_SCOPE_LEVELS = (\"temp\", \"user\", \"app\")\n",
    "\n",
    "\n",
    "# This demonstrates how tools can write to session state using tool_context.\n",
    "# The 'user:' prefix indicates this is user-specific data.\n",
    "def save_userinfo(\n",
    "    tool_context: ToolContext, user_name: str, country: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Tool to record and save user name and country in session state.\n",
    "\n",
    "    Args:\n",
    "        user_name: The username to store in session state\n",
    "        country: The name of the user's country\n",
    "    \"\"\"\n",
    "    # Write to session state using the 'user:' prefix for user data\n",
    "    tool_context.state[\"user:name\"] = user_name\n",
    "    tool_context.state[\"user:country\"] = country\n",
    "\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "\n",
    "# This demonstrates how tools can read from session state.\n",
    "def retrieve_userinfo(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Tool to retrieve user name and country from session state.\n",
    "    \"\"\"\n",
    "    # Read from session state\n",
    "    user_name = tool_context.state.get(\"user:name\", \"Username not found\")\n",
    "    country = tool_context.state.get(\"user:country\", \"Country not found\")\n",
    "\n",
    "    return {\"status\": \"success\", \"user_name\": user_name, \"country\": country}\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tools created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea7f68-d875-4af4-8eef-61db8735abed",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "- Tools can access `tool_context.state` to read/write session state\n",
    "- Use descriptive key prefixes (`user:`, `app:`, `temp:`) for organization\n",
    "- State persists across conversation turns within the same session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6573fd64-eb02-476e-a5b8-82fd2754fb80",
   "metadata": {},
   "source": [
    "### 5.2 Creating an Agent with Session State Tools\n",
    "\n",
    "Now let's create a new agent that has access to our session state management tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba5f3fce-7f97-49ce-8a09-af2651cffd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent with session state tools initialized!\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "APP_NAME = \"default\"\n",
    "USER_ID = \"default\"\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Create an agent with session state tools\n",
    "root_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"\"\"A text chatbot.\n",
    "    Tools for managing user context:\n",
    "    * To record username and country when provided use `save_userinfo` tool. \n",
    "    * To fetch username and country when required use `retrieve_userinfo` tool.\n",
    "    \"\"\",\n",
    "    tools=[save_userinfo, retrieve_userinfo],  # Provide the tools to the agent\n",
    ")\n",
    "\n",
    "# Set up session service and runner\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=root_agent, session_service=session_service, app_name=\"default\")\n",
    "\n",
    "print(\"‚úÖ Agent with session state tools initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a89a3-6958-4ee4-883c-36c0bd21100c",
   "metadata": {},
   "source": [
    "### 5.3 Testing Session State in Action\n",
    "\n",
    "Let's test how the agent uses session state to remember information across conversation turns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1fdc23f0-df03-44db-b683-0987ade569a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: state-demo-session\n",
      "\n",
      "User > Hi there, how are you doing today? What is my name?\n",
      "gemini-2.5-flash-lite >  Hello! I'm doing great. I can't recall your name just yet. Can you tell me what it is?\n",
      "\n",
      "\n",
      "User > My name is Sam. I'm from Poland.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  Nice to meet you, Sam! I'll remember that you're from Poland.\n",
      "\n",
      "User > What is my name? Which country am I from?\n",
      "gemini-2.5-flash-lite >  Your name is Sam and you are from Poland.\n"
     ]
    }
   ],
   "source": [
    "# Test conversation demonstrating session state\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\n",
    "        \"Hi there, how are you doing today? What is my name?\",  # Agent shouldn't know the name yet\n",
    "        \"My name is Sam. I'm from Poland.\",  # Provide name - agent should save it\n",
    "        \"What is my name? Which country am I from?\",  # Agent should recall from session state\n",
    "    ],\n",
    "    \"state-demo-session\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207824fe-8906-4db3-823c-f8b1d7d5ac0d",
   "metadata": {},
   "source": [
    "### 5.4 Inspecting Session State\n",
    "\n",
    "Let's directly inspect the session state to see what's stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54bfbf98-f7cc-4649-88b1-05e318890a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session State Contents:\n",
      "{'user:name': 'Sam', 'user:country': 'Poland'}\n",
      "\n",
      "üîç Notice the 'user:name' and 'user:country' keys storing our data!\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the session and inspect its state\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"state-demo-session\"\n",
    ")\n",
    "\n",
    "print(\"Session State Contents:\")\n",
    "print(session.state)\n",
    "print(\"\\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d1846-a9dd-41b9-b8bf-2b42cf3ee9ae",
   "metadata": {},
   "source": [
    "### 5.5 Session State Isolation\n",
    "\n",
    "As we've already seen, an important characteristic of session state is that it's isolated per session. Let's demonstrate this by starting a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8adabe80-872e-4bfa-b2bd-2c1c5cad47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: new-isolated-session\n",
      "\n",
      "User > Hi there, how are you doing today? What is my name?\n",
      "gemini-2.5-flash-lite >  I'm doing great and ready to assist you! I'm sorry, but I don't have your name. Would you like to tell me your name and country so I can remember it for next time?\n"
     ]
    }
   ],
   "source": [
    "# Start a completely new session - the agent won't know our name\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\"Hi there, how are you doing today? What is my name?\"],\n",
    "    \"new-isolated-session\",\n",
    ")\n",
    "\n",
    "# Expected: The agent won't know the name because this is a different session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e2b02-bee3-4e3c-b797-00f61459ea4b",
   "metadata": {},
   "source": [
    "### 5.6 Cross-Session State Sharing\n",
    "\n",
    "While sessions are isolated by default, you might notice something interesting. Let's check the state of our new session (`new-isolated-session`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a4dce78-5b5a-4e35-8125-4fdd4f67f0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Session State:\n",
      "{'user:name': 'Sam', 'user:country': 'Poland'}\n"
     ]
    }
   ],
   "source": [
    "# Check the state of the new session\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"new-isolated-session\"\n",
    ")\n",
    "\n",
    "print(\"New Session State:\")\n",
    "print(session.state)\n",
    "\n",
    "# Note: Depending on implementation, you might see shared state here.\n",
    "# This is where the distinction between session-specific and user-specific state becomes important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "32fa5384-cb59-4433-b968-996faf0726e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned up old database files\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing database to start fresh (if Notebook is restarted)\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"my_agent_data.db\"):\n",
    "    os.remove(\"my_agent_data.db\")\n",
    "print(\"‚úÖ Cleaned up old database files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee69f7-8565-4f00-a739-be05bb9770e3",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Summary\n",
    "\n",
    "üéâ Congratulations! You've learned the fundamentals of building stateful AI agents:\n",
    "\n",
    "- ‚úÖ **Context Engineering** - You understand how to assemble context for LLMs using Context Compaction\n",
    "- ‚úÖ **Sessions & Events** - You can maintain conversation history across multiple turns\n",
    "- ‚úÖ **Persistent Storage** - You know how to make conversations survive restarts\n",
    "- ‚úÖ **Session State** - You can track structured data during conversations\n",
    "- ‚úÖ **Manual State Management** - You've experienced both the power and limitations of manual approaches\n",
    "- ‚úÖ **Production Considerations** - You're ready to handle real-world challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed383a-72cf-4229-9400-c74f549b2767",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Congratulations! You did it üéâ\n",
    "\n",
    "**‚ÑπÔ∏è Note: No submission required!**\n",
    "\n",
    "This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n",
    "\n",
    "### üìö Learn More\n",
    "\n",
    "Refer to the following documentation to learn more:\n",
    "\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [ADK Sessions](https://google.github.io/adk-docs/)\n",
    "- [ADK Session-State](https://medium.com/google-cloud/2-minute-adk-manage-context-efficiently-with-artifacts-6fcc6683d274)\n",
    "- [ADK Session Compaction](https://google.github.io/adk-docs/context/compaction/#define-compactor)\n",
    "\n",
    "### üéØ Next Steps - Long Term Memory Systems (Part 2)\n",
    "\n",
    "#### Why do we need memory?\n",
    "In this notebook, we manually identified a couple characteristic (username and country) and built tools to manage it. But real conversations involve hundreds of such characteristics:\n",
    "- User preferences and habits\n",
    "- Past interactions and their outcomes\n",
    "- Domain knowledge and expertise levels\n",
    "- Communication styles and patterns\n",
    "- Contextual relationships between topics\n",
    "\n",
    "**The Memory System in ADK automates this entire process**, making it a valuable asset for building truly Context-Aware Agents that can accommodate any user's current and future needs.\n",
    "\n",
    "In the next notebook (Part 2: Memory Management), you'll learn how to:\n",
    "- Enable automatic memory extraction from conversations\n",
    "- Build agents that learn and adapt over time\n",
    "- Create truly personalized experiences at scale\n",
    "- Manage long-term knowledge across sessions\n",
    "\n",
    "Ready to transform your manual state management into an intelligent, automated Memory system? Let's continue to Part 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015c60c-342f-49af-ad5c-b608e46909e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
