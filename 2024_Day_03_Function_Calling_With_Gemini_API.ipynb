{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6beacb-e5ce-4e25-8457-8d481c95fd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "genai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29873fe2-8490-469c-a938-2295c549d2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# loads variables from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6441c5-f0b2-4448-9419-d11e3da99130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY is None:\n",
    "    raise ValueError(\"Environment variable GOOGLE_API_KEY not found!\")\n",
    "\n",
    "print(\"Secret loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab54467-8376-4b25-b78f-03b19ad2695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a retry policy. The model might make multiple consecutive calls automatically\n",
    "# for a complex query, this ensures the client retries if it hits quota limits.\n",
    "from google.api_core import retry\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
    "  genai.models.Models.generate_content = retry.Retry(\n",
    "      predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f276306-c431-493a-8d62-b5cb6bc5c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U ipython-sql sqlalchemy\n",
    "%reload_ext sql\n",
    "%sql sqlite:///2024_Day_03_sample.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4c1d5-ec74-4f2a-9b71-f6183b959354",
   "metadata": {},
   "source": [
    "Create the tables and insert some synthetic data. Feel free to tweak this structure and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9d7cee7-d9e1-45f8-a975-42ca3e9553f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///sample.db\n",
      "Done.\n",
      "Done.\n",
      "Done.\n",
      "3 rows affected.\n",
      "3 rows affected.\n",
      "3 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "-- Create the 'products' table\n",
    "CREATE TABLE IF NOT EXISTS products (\n",
    "  \tproduct_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  \tproduct_name VARCHAR(255) NOT NULL,\n",
    "  \tprice DECIMAL(10, 2) NOT NULL\n",
    "  );\n",
    "\n",
    "-- Create the 'staff' table\n",
    "CREATE TABLE IF NOT EXISTS staff (\n",
    "  \tstaff_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  \tfirst_name VARCHAR(255) NOT NULL,\n",
    "  \tlast_name VARCHAR(255) NOT NULL\n",
    "  );\n",
    "\n",
    "-- Create the 'orders' table\n",
    "CREATE TABLE IF NOT EXISTS orders (\n",
    "  \torder_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  \tcustomer_name VARCHAR(255) NOT NULL,\n",
    "  \tstaff_id INTEGER NOT NULL,\n",
    "  \tproduct_id INTEGER NOT NULL,\n",
    "  \tFOREIGN KEY (staff_id) REFERENCES staff (staff_id),\n",
    "  \tFOREIGN KEY (product_id) REFERENCES products (product_id)\n",
    "  );\n",
    "\n",
    "-- Insert data into the 'products' table\n",
    "INSERT INTO products (product_name, price) VALUES\n",
    "  \t('Laptop', 799.99),\n",
    "  \t('Keyboard', 129.99),\n",
    "  \t('Mouse', 29.99);\n",
    "\n",
    "-- Insert data into the 'staff' table\n",
    "INSERT INTO staff (first_name, last_name) VALUES\n",
    "  \t('Alice', 'Smith'),\n",
    "  \t('Bob', 'Johnson'),\n",
    "  \t('Charlie', 'Williams');\n",
    "\n",
    "-- Insert data into the 'orders' table\n",
    "INSERT INTO orders (customer_name, staff_id, product_id) VALUES\n",
    "  \t('David Lee', 1, 1),\n",
    "  \t('Emily Chen', 2, 2),\n",
    "  \t('Frank Brown', 1, 3);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1550cfd-c4ee-40c1-95da-c5b303c11019",
   "metadata": {},
   "source": [
    "## Define database functions\n",
    "\n",
    "Function calling with Gemini API's Python SDK can be implemented by defining [an OpenAPI schema](https://ai.google.dev/api/caching#Schema) that is passed to the model. You can also define Python functions and let the SDK inspect them to automatically define the schema. In this latter case, it's important that the functions are type annotated and have accurate docstrings that describe what the functions do - the model has no insight into the function body, so the docs function as the interface.\n",
    "\n",
    "By providing three key pieces of functionality - listing tables, describing a table, and executing a query - the LLM (much like a human user) will have the basic tools needed to understand and interrogate the database.\n",
    "\n",
    "Start with a database connection that will be used across all of the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1a78a5d-405a-4896-8488-3e05c9e2eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_file = \"2024_Day_03_sample.db\"\n",
    "db_conn = sqlite3.connect(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaed3125-ce70-41b3-9b53-b8179dc3f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - DB CALL: list_tables()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['products', 'sqlite_sequence', 'staff', 'orders']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first function will list all tables available in the database. Define it, and test it out to ensure it works.\n",
    "\n",
    "def list_tables() -> list[str]:\n",
    "    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n",
    "    # Include print logging statements so you can see when functions are being called.\n",
    "    print(' - DB CALL: list_tables()')\n",
    "\n",
    "    cursor = db_conn.cursor()\n",
    "\n",
    "    # Fetch the table names.\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "    tables = cursor.fetchall()\n",
    "    return [t[0] for t in tables]\n",
    "\n",
    "\n",
    "list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e50c4367-a79e-4ca6-9c45-140c3c83b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - DB CALL: describe_table(products)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('product_id', 'INTEGER'),\n",
       " ('product_name', 'VARCHAR(255)'),\n",
       " ('price', 'DECIMAL(10, 2)')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once the available tables is known, the next step a database user will need is to understand\n",
    "# what columns are available in a given table. Define that too, and test that it works as expected.\n",
    "def describe_table(table_name: str) -> list[tuple[str, str]]:\n",
    "    \"\"\"Look up the table schema.\n",
    "\n",
    "    Returns:\n",
    "      List of columns, where each entry is a tuple of (column, type).\n",
    "    \"\"\"\n",
    "    print(f' - DB CALL: describe_table({table_name})')\n",
    "\n",
    "    cursor = db_conn.cursor()\n",
    "\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "\n",
    "    schema = cursor.fetchall()\n",
    "    # [column index, column name, column type, ...]\n",
    "    return [(col[1], col[2]) for col in schema]\n",
    "\n",
    "\n",
    "describe_table(\"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bc1d8-3421-4e5d-a8f4-ddfbcf30d554",
   "metadata": {},
   "source": [
    "Now that the system knows what tables and columns are present, it has enough information to be able to generate and run a `SELECT` query. Now provide that functionality, and test that it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2e380c7-3828-4662-9e95-c1326b197493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - DB CALL: execute_query(select * from products)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 'Laptop', 799.99),\n",
       " (2, 'Keyboard', 129.99),\n",
       " (3, 'Mouse', 29.99),\n",
       " (4, 'Laptop', 799.99),\n",
       " (5, 'Keyboard', 129.99),\n",
       " (6, 'Mouse', 29.99),\n",
       " (7, 'Laptop', 799.99),\n",
       " (8, 'Keyboard', 129.99),\n",
       " (9, 'Mouse', 29.99),\n",
       " (10, 'Laptop', 799.99),\n",
       " (11, 'Keyboard', 129.99),\n",
       " (12, 'Mouse', 29.99)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_query(sql: str) -> list[list[str]]:\n",
    "    \"\"\"Execute an SQL statement, returning the results.\"\"\"\n",
    "    print(f' - DB CALL: execute_query({sql})')\n",
    "\n",
    "    cursor = db_conn.cursor()\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    return cursor.fetchall()\n",
    "\n",
    "execute_query(\"select * from products\")\n",
    "# Here you can see the previously inserted synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40367a6e-cc21-485f-9704-61b6fc7e7896",
   "metadata": {},
   "source": [
    "## Implement function calls\n",
    "\n",
    "Now you can put it all together in a call to the Gemini API.\n",
    "\n",
    "Function calling works by adding specific messages to a chat session. When function schemas are defined and made available to the model and a conversation is started, instead of returning a text response, the model may return a `function_call` instead. When this happens, the client must respond with a `function_response`, indicating the result of the call, and the conversation can continue on as normal.\n",
    "\n",
    "This function calling interaction normally happens manually, allowing you, the client, to validate and initiate the call. However the Python SDK also supports **automatic function calling**, where the supplied functions will be automatically invoked. This is a powerful feature and should be used with care, such as when the functions have no [side-effects](https://en.wikipedia.org/wiki/Side_effect_(computer_science)).\n",
    "\n",
    "Here's the state diagram representing the conversation flow with function calling. With automatic function calling, the bottom row is executed automatically by the Python SDK. With manual function calling, you write the code to run each step individually.\n",
    "\n",
    "![function calling state diagram](https://codelabs.developers.google.com/static/codelabs/gemini-function-calling/img/gemini-function-calling-overview_1440.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f8261a7-1122-47f2-b808-6ee054cfcfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the Python functions defined above.\n",
    "db_tools = [list_tables, describe_table, execute_query]\n",
    "\n",
    "instruction = \"\"\"You are a helpful chatbot that can interact with an SQL database\n",
    "for a computer store. You will take the users questions and turn them into SQL\n",
    "queries using the tools available. Once you have the information you need, you will\n",
    "answer the user's question using the data returned.\n",
    "\n",
    "Use list_tables to see what tables are present, describe_table to understand the\n",
    "schema, and execute_query to issue an SQL SELECT query.\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Start a chat with automatic function calling enabled.\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=db_tools,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d11ba6-60b9-4e4b-ad14-7dea5c8272a9",
   "metadata": {},
   "source": [
    "Now you can engage in a chat conversation where you can ask about the contents of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6366b95c-65d5-4955-8ba0-665c7292a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - DB CALL: execute_query(SELECT ProductName, Price FROM Products ORDER BY Price ASC LIMIT 1;)\n",
      " - DB CALL: describe_table(Products)\n",
      " - DB CALL: execute_query(SELECT product_name, price FROM Products ORDER BY price ASC LIMIT 1;)\n",
      "\n",
      "The cheapest product is the Mouse, which costs $29.99.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resp = chat.send_message(\"What is the cheapest product?\")\n",
    "print(f\"\\n{resp.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b8ea3-6e46-428a-89eb-866380ecc41e",
   "metadata": {},
   "source": [
    "Explore the chat session and ask your own questions. The 2.0 models are quite capable and can usually answer questions requiring multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3521e2d-3d3e-494a-9bef-b83697375caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - DB CALL: list_tables()\n",
      " - DB CALL: describe_table(products)\n",
      " - DB CALL: describe_table(staff)\n",
      " - DB CALL: describe_table(orders)\n",
      " - DB CALL: execute_query(SELECT product_name FROM products EXCEPT SELECT T1.product_name FROM products T1 INNER JOIN orders T2 ON T1.product_id = T2.product_id INNER JOIN staff T3 ON T2.staff_id = T3.staff_id WHERE T3.first_name = 'Alice')\n",
      "\n",
      "Alice should focus on selling Keyboards. This is because she has not sold any keyboards in the past, so it would round out her portfolio.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=db_tools,\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = chat.send_message('What products should salesperson Alice focus on to round out her portfolio? Explain why.')\n",
    "print(f\"\\n{response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd75d7-d825-4075-a26d-47292de8b2dd",
   "metadata": {},
   "source": [
    "### Inspecting the conversation\n",
    "\n",
    "To see the calls that the model makes, and what the client returns in response, you can inspect the chat history. This helper function will print out each turn along with the relevant fields passed or returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f598421e-ed7d-441d-ade1-ecd83d348b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "  \"What products should salesperson Alice focus on to round out her portfolio? Explain why.\"\n",
      "\n",
      "Model:\n",
      "  Function call: list_tables()\n",
      "\n",
      "User:\n",
      "  Function response:\n",
      "    ['products', 'sqlite_sequence', 'staff', 'orders']\n",
      "\n",
      "Model:\n",
      "  Function call: describe_table(table_name=products)\n",
      "\n",
      "User:\n",
      "  Function response:\n",
      "    [('product_id', 'INTEGER'), ('product_name', 'VARCHAR(255)'), ('price', 'DECIMAL(10, 2)')]\n",
      "\n",
      "Model:\n",
      "  Function call: describe_table(table_name=staff)\n",
      "\n",
      "User:\n",
      "  Function response:\n",
      "    [('staff_id', 'INTEGER'), ('first_name', 'VARCHAR(255)'), ('last_name', 'VARCHAR(255)')]\n",
      "\n",
      "Model:\n",
      "  Function call: describe_table(table_name=orders)\n",
      "\n",
      "User:\n",
      "  Function response:\n",
      "    [('order_id', 'INTEGER'), ('customer_name', 'VARCHAR(255)'), ('staff_id', 'INTEGER'), ('product_id', 'INTEGER')]\n",
      "\n",
      "Model:\n",
      "  Function call: execute_query(sql=SELECT product_name FROM products EXCEPT SELECT T1.product_name FROM products T1 INNER JOIN orders T2 ON T1.product_id = T2.product_id INNER JOIN staff T3 ON T2.staff_id = T3.staff_id WHERE T3.first_name = 'Alice')\n",
      "\n",
      "User:\n",
      "  Function response:\n",
      "    [('Keyboard',)]\n",
      "\n",
      "Model:\n",
      "  \"Alice should focus on selling Keyboards. This is because she has not sold any keyboards in the past, so it would round out her portfolio.\n",
      "\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "def print_chat_turns(chat):\n",
    "    \"\"\"Prints out each turn in the chat history, including function calls and responses.\"\"\"\n",
    "    for event in chat.get_history():\n",
    "        print(f\"{event.role.capitalize()}:\")\n",
    "\n",
    "        for part in event.parts:\n",
    "            if txt := part.text:\n",
    "                print(f'  \"{txt}\"')\n",
    "            elif fn := part.function_call:\n",
    "                args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
    "                print(f\"  Function call: {fn.name}({args})\")\n",
    "            elif resp := part.function_response:\n",
    "                print(\"  Function response:\")\n",
    "                print(textwrap.indent(str(resp.response['result']), \"    \"))\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "print_chat_turns(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b910a8c3-14b6-4554-8729-c3b7cacafcf9",
   "metadata": {},
   "source": [
    "In this output you can see each of the conversational turns that were made. Note that the model doesn't remember anything outside of the chat history, so you can make changes to the database structure or data and the model will respond without needing any code changes - try this out!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c817a9-8882-4780-be89-1eb372eaa50b",
   "metadata": {},
   "source": [
    "## Compositional function calling\n",
    "\n",
    "A powerful new feature in Gemini 2.0 is the model's ability to compose user-provided function calls together while generating code.\n",
    "\n",
    "This means that the model is able to take the available tools, generate code that uses it, and execute it all.\n",
    "\n",
    "The feature requires the Live API, so this step uses different setup code than most of the examples you have seen so far. As the Multimodal Live API is a bi-directional streaming service, everything is set up in advance and then executed. This is a little more complex but the result is quite powerful.\n",
    "\n",
    "First define a function that will handle streaming model output. It will stream text output, handle tool-calling and show the generated code that the model writes and executes to fulfill the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "044e51a7-01f4-4cac-ac66-938caa978001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "\n",
    "async def handle_response(stream, tool_impl=None):\n",
    "  \"\"\"Stream output and handle any tool calls during the session.\"\"\"\n",
    "  all_responses = []\n",
    "\n",
    "  async for msg in stream.receive():\n",
    "    all_responses.append(msg)\n",
    "\n",
    "    if text := msg.text:\n",
    "      # Output any text chunks that are streamed back.\n",
    "      if len(all_responses) < 2 or not all_responses[-2].text:\n",
    "        # Display a header if this is the first text chunk.\n",
    "        display(Markdown('### Text'))\n",
    "\n",
    "      print(text, end='')\n",
    "\n",
    "    elif tool_call := msg.tool_call:\n",
    "      # Handle tool-call requests.\n",
    "      for fc in tool_call.function_calls:\n",
    "        display(Markdown('### Tool call'))\n",
    "\n",
    "        # Execute the tool and collect the result to return to the model.\n",
    "        if callable(tool_impl):\n",
    "          try:\n",
    "            result = tool_impl(**fc.args)\n",
    "          except Exception as e:\n",
    "            result = str(e)\n",
    "        else:\n",
    "          result = 'ok'\n",
    "\n",
    "        tool_response = types.LiveClientToolResponse(\n",
    "            function_responses=[types.FunctionResponse(\n",
    "                name=fc.name,\n",
    "                id=fc.id,\n",
    "                response={'result': result},\n",
    "            )]\n",
    "        )\n",
    "        await stream.send(input=tool_response)\n",
    "\n",
    "    elif msg.server_content and msg.server_content.model_turn:\n",
    "      # Print any messages showing code the model generated and ran.\n",
    "\n",
    "      for part in msg.server_content.model_turn.parts:\n",
    "          if code := part.executable_code:\n",
    "            display(Markdown(\n",
    "                f'### Code\\n```\\n{code.code}\\n```'))\n",
    "\n",
    "          elif result := part.code_execution_result:\n",
    "            display(Markdown(f'### Result: {result.outcome}\\n'\n",
    "                             f'```\\n{pformat(result.output)}\\n```'))\n",
    "\n",
    "          elif img := part.inline_data:\n",
    "            display(Image(img.data))\n",
    "\n",
    "  print()\n",
    "  return all_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143fb8a8-61d5-4b2e-9d02-108963758b8b",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "To learn more about what the Gemini API can do with function calling, check out the [Function calling cookbook](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb) (see `Manual function calling` to understand how function calling works manually) as well as [Function calling config](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling_config.ipynb), which gives you fine-grained control over how function calling is triggered.\n",
    "\n",
    "And stay tuned for day 4, where you will explore using function calling with grounding tools.\n",
    "\n",
    "*- [Mark McD](https://linktr.ee/markmcd)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fc456-d095-4d82-9406-423f58c28523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
